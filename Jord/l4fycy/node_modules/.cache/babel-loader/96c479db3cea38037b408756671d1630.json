{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\n\nvar lexer_1 = require(\"./lexer\");\n\nvar noop_1 = __importDefault(require(\"lodash/noop\"));\n\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\n\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\n\nvar last_1 = __importDefault(require(\"lodash/last\"));\n\nvar reject_1 = __importDefault(require(\"lodash/reject\"));\n\nvar map_1 = __importDefault(require(\"lodash/map\"));\n\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\n\nvar keys_1 = __importDefault(require(\"lodash/keys\"));\n\nvar isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\n\nvar identity_1 = __importDefault(require(\"lodash/identity\"));\n\nvar assign_1 = __importDefault(require(\"lodash/assign\"));\n\nvar reduce_1 = __importDefault(require(\"lodash/reduce\"));\n\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\n\nvar utils_1 = require(\"@chevrotain/utils\");\n\nvar tokens_1 = require(\"./tokens\");\n\nvar lexer_errors_public_1 = require(\"./lexer_errors_public\");\n\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\n\nvar LexerDefinitionErrorType;\n\n(function (LexerDefinitionErrorType) {\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\n\nvar DEFAULT_LEXER_CONFIG = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\n\nvar Lexer =\n/** @class */\nfunction () {\n  function Lexer(lexerDefinition, config) {\n    if (config === void 0) {\n      config = DEFAULT_LEXER_CONFIG;\n    }\n\n    var _this = this;\n\n    this.lexerDefinition = lexerDefinition;\n    this.lexerDefinitionErrors = [];\n    this.lexerDefinitionWarning = [];\n    this.patternIdxToConfig = {};\n    this.charCodeToPatternIdxToConfig = {};\n    this.modes = [];\n    this.emptyGroups = {};\n    this.trackStartLines = true;\n    this.trackEndLines = true;\n    this.hasCustom = false;\n    this.canModeBeOptimized = {}; // Duplicated from the parser's perf trace trait to allow future extraction\n    // of the lexer to a separate package.\n\n    this.TRACE_INIT = function (phaseDesc, phaseImpl) {\n      // No need to optimize this using NOOP pattern because\n      // It is not called in a hot spot...\n      if (_this.traceInitPerf === true) {\n        _this.traceInitIndent++;\n        var indent = new Array(_this.traceInitIndent + 1).join(\"\\t\");\n\n        if (_this.traceInitIndent < _this.traceInitMaxIdent) {\n          console.log(\"\".concat(indent, \"--> <\").concat(phaseDesc, \">\"));\n        }\n\n        var _a = (0, utils_1.timer)(phaseImpl),\n            time = _a.time,\n            value = _a.value;\n        /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n\n\n        var traceMethod = time > 10 ? console.warn : console.log;\n\n        if (_this.traceInitIndent < _this.traceInitMaxIdent) {\n          traceMethod(\"\".concat(indent, \"<-- <\").concat(phaseDesc, \"> time: \").concat(time, \"ms\"));\n        }\n\n        _this.traceInitIndent--;\n        return value;\n      } else {\n        return phaseImpl();\n      }\n    };\n\n    if (typeof config === \"boolean\") {\n      throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" + \"a boolean 2nd argument is no longer supported\");\n    } // todo: defaults func?\n\n\n    this.config = (0, assign_1.default)({}, DEFAULT_LEXER_CONFIG, config);\n    var traceInitVal = this.config.traceInitPerf;\n\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n\n    this.traceInitIndent = -1;\n    this.TRACE_INIT(\"Lexer Constructor\", function () {\n      var actualDefinition;\n      var hasOnlySingleMode = true;\n\n      _this.TRACE_INIT(\"Lexer Config handling\", function () {\n        if (_this.config.lineTerminatorsPattern === DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          _this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\n        } else {\n          if (_this.config.lineTerminatorCharacters === DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n            throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n        }\n\n        _this.trackStartLines = /full|onlyStart/i.test(_this.config.positionTracking);\n        _this.trackEndLines = /full/i.test(_this.config.positionTracking); // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n\n        if ((0, isArray_1.default)(lexerDefinition)) {\n          actualDefinition = {\n            modes: {\n              defaultMode: (0, clone_1.default)(lexerDefinition)\n            },\n            defaultMode: lexer_1.DEFAULT_MODE\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = (0, clone_1.default)(lexerDefinition);\n        }\n      });\n\n      if (_this.config.skipValidations === false) {\n        _this.TRACE_INIT(\"performRuntimeChecks\", function () {\n          _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat((0, lexer_1.performRuntimeChecks)(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n        });\n\n        _this.TRACE_INIT(\"performWarningRuntimeChecks\", function () {\n          _this.lexerDefinitionWarning = _this.lexerDefinitionWarning.concat((0, lexer_1.performWarningRuntimeChecks)(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n        });\n      } // for extra robustness to avoid throwing an none informative error message\n\n\n      actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {}; // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n\n      (0, forEach_1.default)(actualDefinition.modes, function (currModeValue, currModeName) {\n        actualDefinition.modes[currModeName] = (0, reject_1.default)(currModeValue, function (currTokType) {\n          return (0, isUndefined_1.default)(currTokType);\n        });\n      });\n      var allModeNames = (0, keys_1.default)(actualDefinition.modes);\n      (0, forEach_1.default)(actualDefinition.modes, function (currModDef, currModName) {\n        _this.TRACE_INIT(\"Mode: <\".concat(currModName, \"> processing\"), function () {\n          _this.modes.push(currModName);\n\n          if (_this.config.skipValidations === false) {\n            _this.TRACE_INIT(\"validatePatterns\", function () {\n              _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat((0, lexer_1.validatePatterns)(currModDef, allModeNames));\n            });\n          } // If definition errors were encountered, the analysis phase may fail unexpectedly/\n          // Considering a lexer with definition errors may never be used, there is no point\n          // to performing the analysis anyhow...\n\n\n          if ((0, isEmpty_1.default)(_this.lexerDefinitionErrors)) {\n            (0, tokens_1.augmentTokenTypes)(currModDef);\n            var currAnalyzeResult_1;\n\n            _this.TRACE_INIT(\"analyzeTokenTypes\", function () {\n              currAnalyzeResult_1 = (0, lexer_1.analyzeTokenTypes)(currModDef, {\n                lineTerminatorCharacters: _this.config.lineTerminatorCharacters,\n                positionTracking: config.positionTracking,\n                ensureOptimizations: config.ensureOptimizations,\n                safeMode: config.safeMode,\n                tracer: _this.TRACE_INIT\n              });\n            });\n\n            _this.patternIdxToConfig[currModName] = currAnalyzeResult_1.patternIdxToConfig;\n            _this.charCodeToPatternIdxToConfig[currModName] = currAnalyzeResult_1.charCodeToPatternIdxToConfig;\n            _this.emptyGroups = (0, assign_1.default)({}, _this.emptyGroups, currAnalyzeResult_1.emptyGroups);\n            _this.hasCustom = currAnalyzeResult_1.hasCustom || _this.hasCustom;\n            _this.canModeBeOptimized[currModName] = currAnalyzeResult_1.canBeOptimized;\n          }\n        });\n      });\n      _this.defaultMode = actualDefinition.defaultMode;\n\n      if (!(0, isEmpty_1.default)(_this.lexerDefinitionErrors) && !_this.config.deferDefinitionErrorsHandling) {\n        var allErrMessages = (0, map_1.default)(_this.lexerDefinitionErrors, function (error) {\n          return error.message;\n        });\n        var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n        throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n      } // Only print warning if there are no errors, This will avoid pl\n\n\n      (0, forEach_1.default)(_this.lexerDefinitionWarning, function (warningDescriptor) {\n        (0, utils_1.PRINT_WARNING)(warningDescriptor.message);\n      });\n\n      _this.TRACE_INIT(\"Choosing sub-methods implementations\", function () {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (lexer_1.SUPPORT_STICKY) {\n          _this.chopInput = identity_1.default;\n          _this.match = _this.matchWithTest;\n        } else {\n          _this.updateLastIndex = noop_1.default;\n          _this.match = _this.matchWithExec;\n        }\n\n        if (hasOnlySingleMode) {\n          _this.handleModes = noop_1.default;\n        }\n\n        if (_this.trackStartLines === false) {\n          _this.computeNewColumn = identity_1.default;\n        }\n\n        if (_this.trackEndLines === false) {\n          _this.updateTokenEndLineColumnLocation = noop_1.default;\n        }\n\n        if (/full/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createFullToken;\n        } else if (/onlyStart/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(_this.config.positionTracking)) {\n          _this.createTokenInstance = _this.createOffsetOnlyToken;\n        } else {\n          throw Error(\"Invalid <positionTracking> config option: \\\"\".concat(_this.config.positionTracking, \"\\\"\"));\n        }\n\n        if (_this.hasCustom) {\n          _this.addToken = _this.addTokenUsingPush;\n          _this.handlePayload = _this.handlePayloadWithCustom;\n        } else {\n          _this.addToken = _this.addTokenUsingMemberAccess;\n          _this.handlePayload = _this.handlePayloadNoCustom;\n        }\n      });\n\n      _this.TRACE_INIT(\"Failed Optimization Warnings\", function () {\n        var unOptimizedModes = (0, reduce_1.default)(_this.canModeBeOptimized, function (cannotBeOptimized, canBeOptimized, modeName) {\n          if (canBeOptimized === false) {\n            cannotBeOptimized.push(modeName);\n          }\n\n          return cannotBeOptimized;\n        }, []);\n\n        if (config.ensureOptimizations && !(0, isEmpty_1.default)(unOptimizedModes)) {\n          throw Error(\"Lexer Modes: < \".concat(unOptimizedModes.join(\", \"), \" > cannot be optimized.\\n\") + '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' + \"\\t Or inspect the console log for details on how to resolve these issues.\");\n        }\n      });\n\n      _this.TRACE_INIT(\"clearRegExpParserCache\", function () {\n        (0, reg_exp_parser_1.clearRegExpParserCache)();\n      });\n\n      _this.TRACE_INIT(\"toFastProperties\", function () {\n        (0, utils_1.toFastProperties)(_this);\n      });\n    });\n  }\n\n  Lexer.prototype.tokenize = function (text, initialMode) {\n    if (initialMode === void 0) {\n      initialMode = this.defaultMode;\n    }\n\n    if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n      var allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, function (error) {\n        return error.message;\n      });\n      var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n      throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n    }\n\n    return this.tokenizeInternal(text, initialMode);\n  }; // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n\n\n  Lexer.prototype.tokenizeInternal = function (text, initialMode) {\n    var _this = this;\n\n    var i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n    var orgText = text;\n    var orgLength = orgText.length;\n    var offset = 0;\n    var matchedTokensIndex = 0; // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n\n    var guessedNumberOfTokens = this.hasCustom ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n    : Math.floor(text.length / 10);\n    var matchedTokens = new Array(guessedNumberOfTokens);\n    var errors = [];\n    var line = this.trackStartLines ? 1 : undefined;\n    var column = this.trackStartLines ? 1 : undefined;\n    var groups = (0, lexer_1.cloneEmptyGroups)(this.emptyGroups);\n    var trackLines = this.trackStartLines;\n    var lineTerminatorPattern = this.config.lineTerminatorsPattern;\n    var currModePatternsLength = 0;\n    var patternIdxToConfig = [];\n    var currCharCodeToPatternIdxToConfig = [];\n    var modeStack = [];\n    var emptyArray = [];\n    Object.freeze(emptyArray);\n    var getPossiblePatterns;\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n\n    function getPossiblePatternsOptimized(charCode) {\n      var optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(charCode);\n      var possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n\n    var pop_mode = function pop_mode(popToken) {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (modeStack.length === 1 && // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n      // So no error should occur.\n      popToken.tokenType.PUSH_MODE === undefined) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        var msg_1 = _this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg_1\n        });\n      } else {\n        modeStack.pop();\n        var newMode = (0, last_1.default)(modeStack);\n        patternIdxToConfig = _this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig = _this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        var modeCanBeOptimized = _this.canModeBeOptimized[newMode] && _this.config.safeMode === false;\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n\n    function push_mode(newMode) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n      currModePatternsLength = patternIdxToConfig.length;\n      var modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    } // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n\n\n    push_mode.call(this, initialMode);\n    var currConfig;\n\n    while (offset < orgLength) {\n      matchedImage = null;\n      var nextCharCode = orgText.charCodeAt(offset);\n      var chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      var chosenPatternsLength = chosenPatternIdxToConfig.length;\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        var currPattern = currConfig.pattern;\n        payload = null; // manually in-lined because > 600 chars won't be in-lined in V8\n\n        var singleCharCode = currConfig.short;\n\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = currPattern.exec(orgText, offset, matchedTokens, groups);\n\n          if (match !== null) {\n            matchedImage = match[0];\n\n            if (match.payload !== undefined) {\n              payload = match.payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern, offset);\n          matchedImage = this.match(currPattern, text, offset);\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            var longerAltLength = longerAlt.length;\n\n            for (k = 0; k < longerAltLength; k++) {\n              var longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              var longerAltPattern = longerAltConfig.pattern;\n              altPayload = null; // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n\n              if (longerAltConfig.isCustom === true) {\n                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n\n                if (match !== null) {\n                  matchAltImage = match[0];\n\n                  if (match.payload !== undefined) {\n                    altPayload = match.payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern, offset);\n                matchAltImage = this.match(longerAltPattern, text, offset);\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig; // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n\n                break;\n              }\n            }\n          }\n\n          break;\n        }\n      } // successful match\n\n\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx; // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n\n          newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n          this.handlePayload(newToken, payload); // TODO: optimize NOOP in case there are no special groups?\n\n          if (group === false) {\n            matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength; // TODO: with newlines the column may be assigned twice\n\n        column = this.computeNewColumn(column, imageLength);\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          var numOfLTsInMatch = 0;\n          var foundTerminator = void 0;\n          var lastLTEndOffset = void 0;\n          lineTerminatorPattern.lastIndex = 0;\n\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n\n          if (numOfLTsInMatch !== 0) {\n            line = line + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset;\n            this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n          }\n        } // will be NOOP if no modes present\n\n\n        this.handleModes(currConfig, pop_mode, push_mode, newToken);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        var errorStartOffset = offset;\n        var errorLine = line;\n        var errorColumn = column;\n        var foundResyncPoint = false;\n\n        while (!foundResyncPoint && offset < orgLength) {\n          // drop chars until we succeed in matching something\n          droppedChar = orgText.charCodeAt(offset); // Identity Func (when sticky flag is enabled)\n\n          text = this.chopInput(text, 1);\n          offset++;\n\n          for (j = 0; j < currModePatternsLength; j++) {\n            var currConfig_1 = patternIdxToConfig[j];\n            var currPattern = currConfig_1.pattern; // manually in-lined because > 600 chars won't be in-lined in V8\n\n            var singleCharCode = currConfig_1.short;\n\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig_1.isCustom === true) {\n              foundResyncPoint = currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n            } else {\n              this.updateLastIndex(currPattern, offset);\n              foundResyncPoint = currPattern.exec(text) !== null;\n            }\n\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset; // at this point we either re-synced or reached the end of the input text\n\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        });\n      }\n    } // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n\n\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors\n    };\n  };\n\n  Lexer.prototype.handleModes = function (config, pop_mode, push_mode, newToken) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      var pushMode = config.push;\n      pop_mode(newToken);\n\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  };\n\n  Lexer.prototype.chopInput = function (text, length) {\n    return text.substring(length);\n  };\n\n  Lexer.prototype.updateLastIndex = function (regExp, newLastIndex) {\n    regExp.lastIndex = newLastIndex;\n  }; // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n\n\n  Lexer.prototype.updateTokenEndLineColumnLocation = function (newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n    var lastCharIsLT, fixForEndingInLT;\n\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT; // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      } // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n\n    }\n  };\n\n  Lexer.prototype.computeNewColumn = function (oldColumn, imageLength) {\n    return oldColumn + imageLength;\n  };\n\n  Lexer.prototype.createOffsetOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n\n  Lexer.prototype.createStartOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      startLine: startLine,\n      startColumn: startColumn,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n\n  Lexer.prototype.createFullToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n    return {\n      image: image,\n      startOffset: startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine: startLine,\n      endLine: startLine,\n      startColumn: startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx: tokenTypeIdx,\n      tokenType: tokenType\n    };\n  };\n\n  Lexer.prototype.addTokenUsingPush = function (tokenVector, index, tokenToAdd) {\n    tokenVector.push(tokenToAdd);\n    return index;\n  };\n\n  Lexer.prototype.addTokenUsingMemberAccess = function (tokenVector, index, tokenToAdd) {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  };\n\n  Lexer.prototype.handlePayloadNoCustom = function (token, payload) {};\n\n  Lexer.prototype.handlePayloadWithCustom = function (token, payload) {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  };\n\n  Lexer.prototype.matchWithTest = function (pattern, text, offset) {\n    var found = pattern.test(text);\n\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n\n    return null;\n  };\n\n  Lexer.prototype.matchWithExec = function (pattern, text) {\n    var regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  };\n\n  Lexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" + \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n  Lexer.NA = /NOT_APPLICABLE/;\n  return Lexer;\n}();\n\nexports.Lexer = Lexer;","map":{"version":3,"mappings":";;;;;;;;;;;;;AAAA;;AAaA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AAWA;;AACA;;AAQA,IAAYA,wBAAZ;;AAAA,WAAYA,wBAAZ,EAAoC;EAClCA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;EACAA;AACD,CAlBD,EAAYA,wBAAwB,GAAxBC,wEAAwB,EAAxB,CAAZ;;AAwBA,IAAMC,oBAAoB,GAA2B;EACnDC,6BAA6B,EAAE,KADoB;EAEnDC,gBAAgB,EAAE,MAFiC;EAGnDC,sBAAsB,EAAE,WAH2B;EAInDC,wBAAwB,EAAE,CAAC,IAAD,EAAO,IAAP,CAJyB;EAKnDC,mBAAmB,EAAE,KAL8B;EAMnDC,QAAQ,EAAE,KANyC;EAOnDC,oBAAoB,EAAEC,+CAP6B;EAQnDC,aAAa,EAAE,KARoC;EASnDC,eAAe,EAAE;AATkC,CAArD;AAYAC,MAAM,CAACC,MAAP,CAAcZ,oBAAd;;AAEA;AAAA;AAAA;EA4BE,eACYa,eADZ,EAEEC,MAFF,EAE6C;IAA3C;MAAAA;IAA2C;;IAF7C;;IACY;IAvBL,6BAAiD,EAAjD;IACA,8BAAkD,EAAlD;IAEG,0BAAuD,EAAvD;IACA,oCAEN,EAFM;IAIA,aAAkB,EAAlB;IAEA,mBAA+C,EAA/C;IAGF,uBAA2B,IAA3B;IACA,qBAAyB,IAAzB;IACA,iBAAqB,KAArB;IACA,0BAA8C,EAA9C,CAQqC,CAuzB7C;IACA;;IACA,kBAAa,UAAIC,SAAJ,EAAuBC,SAAvB,EAAyC;MACpD;MACA;MACA,IAAIC,KAAI,CAACR,aAAL,KAAuB,IAA3B,EAAiC;QAC/BQ,KAAI,CAACC,eAAL;QACA,IAAMC,MAAM,GAAG,IAAIC,KAAJ,CAAUH,KAAI,CAACC,eAAL,GAAuB,CAAjC,EAAoCG,IAApC,CAAyC,IAAzC,CAAf;;QACA,IAAIJ,KAAI,CAACC,eAAL,GAAuBD,KAAI,CAACK,iBAAhC,EAAmD;UACjDC,OAAO,CAACC,GAAR,CAAY,UAAGL,MAAH,EAAS,OAAT,EAASM,MAAT,CAAiBV,SAAjB,EAA0B,GAA1B,CAAZ;QACD;;QACK,SAAkB,mBAAMC,SAAN,CAAlB;QAAA,IAAEU,IAAI,UAAN;QAAA,IAAQC,KAAK,WAAb;QACN;;;QACA,IAAMC,WAAW,GAAGF,IAAI,GAAG,EAAP,GAAYH,OAAO,CAACM,IAApB,GAA2BN,OAAO,CAACC,GAAvD;;QACA,IAAIP,KAAI,CAACC,eAAL,GAAuBD,KAAI,CAACK,iBAAhC,EAAmD;UACjDM,WAAW,CAAC,UAAGT,MAAH,EAAS,OAAT,EAASM,MAAT,CAAiBV,SAAjB,EAA0B,UAA1B,EAA0BU,MAA1B,CAAqCC,IAArC,EAAyC,IAAzC,CAAD,CAAX;QACD;;QACDT,KAAI,CAACC,eAAL;QACA,OAAOS,KAAP;MACD,CAdD,MAcO;QACL,OAAOX,SAAS,EAAhB;MACD;IACF,CApBD;;IAvzBE,IAAI,OAAOF,MAAP,KAAkB,SAAtB,EAAiC;MAC/B,MAAMgB,KAAK,CACT,kFACE,+CAFO,CAAX;IAID,CAP0C,CAS3C;;;IACA,KAAKhB,MAAL,GAAc,sBAAO,EAAP,EAAWd,oBAAX,EAAiCc,MAAjC,CAAd;IAEA,IAAMiB,YAAY,GAAG,KAAKjB,MAAL,CAAYL,aAAjC;;IACA,IAAIsB,YAAY,KAAK,IAArB,EAA2B;MACzB,KAAKT,iBAAL,GAAyBU,QAAzB;MACA,KAAKvB,aAAL,GAAqB,IAArB;IACD,CAHD,MAGO,IAAI,OAAOsB,YAAP,KAAwB,QAA5B,EAAsC;MAC3C,KAAKT,iBAAL,GAAyBS,YAAzB;MACA,KAAKtB,aAAL,GAAqB,IAArB;IACD;;IACD,KAAKS,eAAL,GAAuB,CAAC,CAAxB;IAEA,KAAKe,UAAL,CAAgB,mBAAhB,EAAqC;MACnC,IAAIC,gBAAJ;MACA,IAAIC,iBAAiB,GAAG,IAAxB;;MACAlB,KAAI,CAACgB,UAAL,CAAgB,uBAAhB,EAAyC;QACvC,IACEhB,KAAI,CAACH,MAAL,CAAYX,sBAAZ,KACAH,oBAAoB,CAACG,sBAFvB,EAGE;UACA;UACAc,KAAI,CAACH,MAAL,CAAYX,sBAAZ,GAAqCiC,qCAArC;QACD,CAND,MAMO;UACL,IACEnB,KAAI,CAACH,MAAL,CAAYV,wBAAZ,KACAJ,oBAAoB,CAACI,wBAFvB,EAGE;YACA,MAAM0B,KAAK,CACT,8EACE,yGAFO,CAAX;UAID;QACF;;QAED,IAAIhB,MAAM,CAACR,QAAP,IAAmBQ,MAAM,CAACT,mBAA9B,EAAmD;UACjD,MAAMyB,KAAK,CACT,oEADS,CAAX;QAGD;;QAEDb,KAAI,CAACoB,eAAL,GAAuB,kBAAkBC,IAAlB,CACrBrB,KAAI,CAACH,MAAL,CAAYZ,gBADS,CAAvB;QAGAe,KAAI,CAACsB,aAAL,GAAqB,QAAQD,IAAR,CAAarB,KAAI,CAACH,MAAL,CAAYZ,gBAAzB,CAArB,CA5BuC,CA8BvC;;QACA,IAAI,uBAAQW,eAAR,CAAJ,EAA8B;UAC5BqB,gBAAgB,GAAG;YACjBM,KAAK,EAAE;cAAEC,WAAW,EAAE,qBAAM5B,eAAN;YAAf,CADU;YAEjB4B,WAAW,EAAEL;UAFI,CAAnB;QAID,CALD,MAKO;UACL;UACAD,iBAAiB,GAAG,KAApB;UACAD,gBAAgB,GAAG,qBAAiCrB,eAAjC,CAAnB;QACD;MACF,CAzCD;;MA2CA,IAAII,KAAI,CAACH,MAAL,CAAYJ,eAAZ,KAAgC,KAApC,EAA2C;QACzCO,KAAI,CAACgB,UAAL,CAAgB,sBAAhB,EAAwC;UACtChB,KAAI,CAACyB,qBAAL,GAA6BzB,KAAI,CAACyB,qBAAL,CAA2BjB,MAA3B,CAC3B,kCACES,gBADF,EAEEjB,KAAI,CAACoB,eAFP,EAGEpB,KAAI,CAACH,MAAL,CAAYV,wBAHd,CAD2B,CAA7B;QAOD,CARD;;QAUAa,KAAI,CAACgB,UAAL,CAAgB,6BAAhB,EAA+C;UAC7ChB,KAAI,CAAC0B,sBAAL,GAA8B1B,KAAI,CAAC0B,sBAAL,CAA4BlB,MAA5B,CAC5B,yCACES,gBADF,EAEEjB,KAAI,CAACoB,eAFP,EAGEpB,KAAI,CAACH,MAAL,CAAYV,wBAHd,CAD4B,CAA9B;QAOD,CARD;MASD,CAlEkC,CAoEnC;;;MACA8B,gBAAgB,CAACM,KAAjB,GAAyBN,gBAAgB,CAACM,KAAjB,GACrBN,gBAAgB,CAACM,KADI,GAErB,EAFJ,CArEmC,CAyEnC;MACA;;MACA,uBAAQN,gBAAgB,CAACM,KAAzB,EAAgC,UAACI,aAAD,EAAgBC,YAAhB,EAA4B;QAC1DX,gBAAgB,CAACM,KAAjB,CAAuBK,YAAvB,IAAuC,sBACrCD,aADqC,EAErC,UAACE,WAAD,EAAY;UAAK,kCAAYA,WAAZ;QAAwB,CAFJ,CAAvC;MAID,CALD;MAOA,IAAMC,YAAY,GAAG,oBAAKb,gBAAgB,CAACM,KAAtB,CAArB;MAEA,uBACEN,gBAAgB,CAACM,KADnB,EAEE,UAACQ,UAAD,EAA0BC,WAA1B,EAAqC;QACnChC,KAAI,CAACgB,UAAL,CAAgB,iBAAUgB,WAAV,EAAqB,cAArB,CAAhB,EAAqD;UACnDhC,KAAI,CAACuB,KAAL,CAAWU,IAAX,CAAgBD,WAAhB;;UAEA,IAAIhC,KAAI,CAACH,MAAL,CAAYJ,eAAZ,KAAgC,KAApC,EAA2C;YACzCO,KAAI,CAACgB,UAAL,CAAgB,kBAAhB,EAAoC;cAClChB,KAAI,CAACyB,qBAAL,GAA6BzB,KAAI,CAACyB,qBAAL,CAA2BjB,MAA3B,CAC3B,8BAAiBuB,UAAjB,EAA6BD,YAA7B,CAD2B,CAA7B;YAGD,CAJD;UAKD,CATkD,CAWnD;UACA;UACA;;;UACA,IAAI,uBAAQ9B,KAAI,CAACyB,qBAAb,CAAJ,EAAyC;YACvC,gCAAkBM,UAAlB;YAEA,IAAIG,mBAAJ;;YACAlC,KAAI,CAACgB,UAAL,CAAgB,mBAAhB,EAAqC;cACnCkB,mBAAiB,GAAG,+BAAkBH,UAAlB,EAA8B;gBAChD5C,wBAAwB,EACtBa,KAAI,CAACH,MAAL,CAAYV,wBAFkC;gBAGhDF,gBAAgB,EAAEY,MAAM,CAACZ,gBAHuB;gBAIhDG,mBAAmB,EAAES,MAAM,CAACT,mBAJoB;gBAKhDC,QAAQ,EAAEQ,MAAM,CAACR,QAL+B;gBAMhD8C,MAAM,EAAEnC,KAAI,CAACgB;cANmC,CAA9B,CAApB;YAQD,CATD;;YAWAhB,KAAI,CAACoC,kBAAL,CAAwBJ,WAAxB,IACEE,mBAAiB,CAACE,kBADpB;YAGApC,KAAI,CAACqC,4BAAL,CAAkCL,WAAlC,IACEE,mBAAiB,CAACG,4BADpB;YAGArC,KAAI,CAACsC,WAAL,GAAmB,sBACjB,EADiB,EAEjBtC,KAAI,CAACsC,WAFY,EAGjBJ,mBAAiB,CAACI,WAHD,CAAnB;YAMAtC,KAAI,CAACuC,SAAL,GAAiBL,mBAAiB,CAACK,SAAlB,IAA+BvC,KAAI,CAACuC,SAArD;YAEAvC,KAAI,CAACwC,kBAAL,CAAwBR,WAAxB,IACEE,mBAAiB,CAACO,cADpB;UAED;QACF,CA9CD;MA+CD,CAlDH;MAqDAzC,KAAI,CAACwB,WAAL,GAAmBP,gBAAgB,CAACO,WAApC;;MAEA,IACE,CAAC,uBAAQxB,KAAI,CAACyB,qBAAb,CAAD,IACA,CAACzB,KAAI,CAACH,MAAL,CAAYb,6BAFf,EAGE;QACA,IAAM0D,cAAc,GAAG,mBAAI1C,KAAI,CAACyB,qBAAT,EAAgC,UAACkB,KAAD,EAAM;UAC3D,OAAOA,KAAK,CAACC,OAAb;QACD,CAFsB,CAAvB;QAGA,IAAMC,oBAAoB,GAAGH,cAAc,CAACtC,IAAf,CAC3B,2BAD2B,CAA7B;QAGA,MAAM,IAAIS,KAAJ,CACJ,8CAA8CgC,oBAD1C,CAAN;MAGD,CAxJkC,CA0JnC;;;MACA,uBAAQ7C,KAAI,CAAC0B,sBAAb,EAAqC,UAACoB,iBAAD,EAAkB;QACrD,2BAAcA,iBAAiB,CAACF,OAAhC;MACD,CAFD;;MAIA5C,KAAI,CAACgB,UAAL,CAAgB,sCAAhB,EAAwD;QACtD;QACA;QACA;QACA,IAAIG,sBAAJ,EAAoB;UAClBnB,KAAI,CAAC+C,SAAL,GAAsBC,kBAAtB;UACAhD,KAAI,CAACiD,KAAL,GAAajD,KAAI,CAACkD,aAAlB;QACD,CAHD,MAGO;UACLlD,KAAI,CAACmD,eAAL,GAAuBC,cAAvB;UACApD,KAAI,CAACiD,KAAL,GAAajD,KAAI,CAACqD,aAAlB;QACD;;QAED,IAAInC,iBAAJ,EAAuB;UACrBlB,KAAI,CAACsD,WAAL,GAAmBF,cAAnB;QACD;;QAED,IAAIpD,KAAI,CAACoB,eAAL,KAAyB,KAA7B,EAAoC;UAClCpB,KAAI,CAACuD,gBAAL,GAAwBP,kBAAxB;QACD;;QAED,IAAIhD,KAAI,CAACsB,aAAL,KAAuB,KAA3B,EAAkC;UAChCtB,KAAI,CAACwD,gCAAL,GAAwCJ,cAAxC;QACD;;QAED,IAAI,QAAQ/B,IAAR,CAAarB,KAAI,CAACH,MAAL,CAAYZ,gBAAzB,CAAJ,EAAgD;UAC9Ce,KAAI,CAACyD,mBAAL,GAA2BzD,KAAI,CAAC0D,eAAhC;QACD,CAFD,MAEO,IAAI,aAAarC,IAAb,CAAkBrB,KAAI,CAACH,MAAL,CAAYZ,gBAA9B,CAAJ,EAAqD;UAC1De,KAAI,CAACyD,mBAAL,GAA2BzD,KAAI,CAAC2D,oBAAhC;QACD,CAFM,MAEA,IAAI,cAActC,IAAd,CAAmBrB,KAAI,CAACH,MAAL,CAAYZ,gBAA/B,CAAJ,EAAsD;UAC3De,KAAI,CAACyD,mBAAL,GAA2BzD,KAAI,CAAC4D,qBAAhC;QACD,CAFM,MAEA;UACL,MAAM/C,KAAK,CACT,sDAA8Cb,KAAI,CAACH,MAAL,CAAYZ,gBAA1D,EAA0E,IAA1E,CADS,CAAX;QAGD;;QAED,IAAIe,KAAI,CAACuC,SAAT,EAAoB;UAClBvC,KAAI,CAAC6D,QAAL,GAAgB7D,KAAI,CAAC8D,iBAArB;UACA9D,KAAI,CAAC+D,aAAL,GAAqB/D,KAAI,CAACgE,uBAA1B;QACD,CAHD,MAGO;UACLhE,KAAI,CAAC6D,QAAL,GAAgB7D,KAAI,CAACiE,yBAArB;UACAjE,KAAI,CAAC+D,aAAL,GAAqB/D,KAAI,CAACkE,qBAA1B;QACD;MACF,CA3CD;;MA6CAlE,KAAI,CAACgB,UAAL,CAAgB,8BAAhB,EAAgD;QAC9C,IAAMmD,gBAAgB,GAAG,sBACvBnE,KAAI,CAACwC,kBADkB,EAEvB,UAAC4B,iBAAD,EAAoB3B,cAApB,EAAoC4B,QAApC,EAA4C;UAC1C,IAAI5B,cAAc,KAAK,KAAvB,EAA8B;YAC5B2B,iBAAiB,CAACnC,IAAlB,CAAuBoC,QAAvB;UACD;;UACD,OAAOD,iBAAP;QACD,CAPsB,EAQvB,EARuB,CAAzB;;QAWA,IAAIvE,MAAM,CAACT,mBAAP,IAA8B,CAAC,uBAAQ+E,gBAAR,CAAnC,EAA8D;UAC5D,MAAMtD,KAAK,CACT,yBAAkBsD,gBAAgB,CAAC/D,IAAjB,CAChB,IADgB,CAAlB,EAEC,2BAFD,IAGE,6HAHF,GAIE,2EALO,CAAX;QAOD;MACF,CArBD;;MAuBAJ,KAAI,CAACgB,UAAL,CAAgB,wBAAhB,EAA0C;QACxC;MACD,CAFD;;MAIAhB,KAAI,CAACgB,UAAL,CAAgB,kBAAhB,EAAoC;QAClC,8BAAiBhB,KAAjB;MACD,CAFD;IAGD,CA1OD;EA2OD;;EAEMsE,2BAAP,UACEC,IADF,EAEEC,WAFF,EAEwC;IAAtC;MAAAA,cAAsB,KAAKhD,WAA3B;IAAsC;;IAEtC,IAAI,CAAC,uBAAQ,KAAKC,qBAAb,CAAL,EAA0C;MACxC,IAAMiB,cAAc,GAAG,mBAAI,KAAKjB,qBAAT,EAAgC,UAACkB,KAAD,EAAM;QAC3D,OAAOA,KAAK,CAACC,OAAb;MACD,CAFsB,CAAvB;MAGA,IAAMC,oBAAoB,GAAGH,cAAc,CAACtC,IAAf,CAC3B,2BAD2B,CAA7B;MAGA,MAAM,IAAIS,KAAJ,CACJ,yEACEgC,oBAFE,CAAN;IAID;;IAED,OAAO,KAAK4B,gBAAL,CAAsBF,IAAtB,EAA4BC,WAA5B,CAAP;EACD,CAlBM,CAjST,CAqTE;EACA;EACA;EACA;;;EACQF,mCAAR,UAAyBC,IAAzB,EAAuCC,WAAvC,EAA0D;IAA1D;;IACE,IAAIE,CAAJ,EACEC,CADF,EAEEC,CAFF,EAGEC,aAHF,EAIEC,SAJF,EAKEC,YALF,EAMEC,OANF,EAOEC,UAPF,EAQEC,WARF,EASEC,KATF,EAUEC,OAVF,EAWEC,QAXF,EAYEC,SAZF,EAaEC,WAbF,EAcEC,GAdF,EAeEvC,KAfF;IAgBA,IAAMwC,OAAO,GAAGlB,IAAhB;IACA,IAAMmB,SAAS,GAAGD,OAAO,CAACE,MAA1B;IACA,IAAIC,MAAM,GAAG,CAAb;IACA,IAAIC,kBAAkB,GAAG,CAAzB,CApBwD,CAqBxD;IACA;IACA;IACA;;IACA,IAAMC,qBAAqB,GAAG,KAAKvD,SAAL,GAC1B,CAD0B,CACxB;IADwB,EAE1BwD,IAAI,CAACC,KAAL,CAAWzB,IAAI,CAACoB,MAAL,GAAc,EAAzB,CAFJ;IAGA,IAAMM,aAAa,GAAG,IAAI9F,KAAJ,CAAU2F,qBAAV,CAAtB;IACA,IAAMI,MAAM,GAAmB,EAA/B;IACA,IAAIC,IAAI,GAAG,KAAK/E,eAAL,GAAuB,CAAvB,GAA2BgF,SAAtC;IACA,IAAIC,MAAM,GAAG,KAAKjF,eAAL,GAAuB,CAAvB,GAA2BgF,SAAxC;IACA,IAAME,MAAM,GAAQ,8BAAiB,KAAKhE,WAAtB,CAApB;IACA,IAAMiE,UAAU,GAAG,KAAKnF,eAAxB;IACA,IAAMoF,qBAAqB,GAAG,KAAK3G,MAAL,CAAYX,sBAA1C;IAEA,IAAIuH,sBAAsB,GAAG,CAA7B;IACA,IAAIrE,kBAAkB,GAAqB,EAA3C;IACA,IAAIsE,gCAAgC,GAEhC,EAFJ;IAIA,IAAMC,SAAS,GAAa,EAA5B;IAEA,IAAMC,UAAU,GAAqB,EAArC;IACAlH,MAAM,CAACC,MAAP,CAAciH,UAAd;IACA,IAAIC,mBAAJ;;IAEA,SAASC,uBAAT,GAAgC;MAC9B,OAAO1E,kBAAP;IACD;;IAED,SAAS2E,4BAAT,CAAsCC,QAAtC,EAAsD;MACpD,IAAMC,gBAAgB,GAAG,sCAAyBD,QAAzB,CAAzB;MACA,IAAME,gBAAgB,GACpBR,gCAAgC,CAACO,gBAAD,CADlC;;MAEA,IAAIC,gBAAgB,KAAKd,SAAzB,EAAoC;QAClC,OAAOQ,UAAP;MACD,CAFD,MAEO;QACL,OAAOM,gBAAP;MACD;IACF;;IAED,IAAMC,QAAQ,GAAG,SAAXA,QAAW,CAACC,QAAD,EAAiB;MAChC;MACA,IACET,SAAS,CAAChB,MAAV,KAAqB,CAArB,IACA;MACA;MACAyB,QAAQ,CAACC,SAAT,CAAmBC,SAAnB,KAAiClB,SAJnC,EAKE;QACA;QACA;QACA,IAAMmB,KAAG,GACPvH,KAAI,CAACH,MAAL,CAAYP,oBAAZ,CAAiCkI,gCAAjC,CACEJ,QADF,CADF;;QAKAlB,MAAM,CAACjE,IAAP,CAAY;UACV2D,MAAM,EAAEwB,QAAQ,CAACK,WADP;UAEVtB,IAAI,EAAEiB,QAAQ,CAACM,SAFL;UAGVrB,MAAM,EAAEe,QAAQ,CAACO,WAHP;UAIVhC,MAAM,EAAEyB,QAAQ,CAACQ,KAAT,CAAejC,MAJb;UAKV/C,OAAO,EAAE2E;QALC,CAAZ;MAOD,CApBD,MAoBO;QACLZ,SAAS,CAACkB,GAAV;QACA,IAAMC,OAAO,GAAG,oBAAKnB,SAAL,CAAhB;QACAvE,kBAAkB,GAAGpC,KAAI,CAACoC,kBAAL,CAAwB0F,OAAxB,CAArB;QACApB,gCAAgC,GAC9B1G,KAAI,CAACqC,4BAAL,CAAkCyF,OAAlC,CADF;QAEArB,sBAAsB,GAAGrE,kBAAkB,CAACuD,MAA5C;QACA,IAAMoC,kBAAkB,GACtB/H,KAAI,CAACwC,kBAAL,CAAwBsF,OAAxB,KAAoC9H,KAAI,CAACH,MAAL,CAAYR,QAAZ,KAAyB,KAD/D;;QAGA,IAAIqH,gCAAgC,IAAIqB,kBAAxC,EAA4D;UAC1DlB,mBAAmB,GAAGE,4BAAtB;QACD,CAFD,MAEO;UACLF,mBAAmB,GAAGC,uBAAtB;QACD;MACF;IACF,CAtCD;;IAwCA,SAASkB,SAAT,CAAgCF,OAAhC,EAA+C;MAC7CnB,SAAS,CAAC1E,IAAV,CAAe6F,OAAf;MACApB,gCAAgC,GAC9B,KAAKrE,4BAAL,CAAkCyF,OAAlC,CADF;MAGA1F,kBAAkB,GAAG,KAAKA,kBAAL,CAAwB0F,OAAxB,CAArB;MACArB,sBAAsB,GAAGrE,kBAAkB,CAACuD,MAA5C;MAEAc,sBAAsB,GAAGrE,kBAAkB,CAACuD,MAA5C;MACA,IAAMoC,kBAAkB,GACtB,KAAKvF,kBAAL,CAAwBsF,OAAxB,KAAoC,KAAKjI,MAAL,CAAYR,QAAZ,KAAyB,KAD/D;;MAGA,IAAIqH,gCAAgC,IAAIqB,kBAAxC,EAA4D;QAC1DlB,mBAAmB,GAAGE,4BAAtB;MACD,CAFD,MAEO;QACLF,mBAAmB,GAAGC,uBAAtB;MACD;IACF,CAxHuD,CA0HxD;IACA;;;IACAkB,SAAS,CAACC,IAAV,CAAe,IAAf,EAAqBzD,WAArB;IAEA,IAAI0D,UAAJ;;IAEA,OAAOtC,MAAM,GAAGF,SAAhB,EAA2B;MACzBX,YAAY,GAAG,IAAf;MAEA,IAAMoD,YAAY,GAAG1C,OAAO,CAAC2C,UAAR,CAAmBxC,MAAnB,CAArB;MACA,IAAMyC,wBAAwB,GAAGxB,mBAAmB,CAACsB,YAAD,CAApD;MACA,IAAMG,oBAAoB,GAAGD,wBAAwB,CAAC1C,MAAtD;;MAEA,KAAKjB,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAG4D,oBAAhB,EAAsC5D,CAAC,EAAvC,EAA2C;QACzCwD,UAAU,GAAGG,wBAAwB,CAAC3D,CAAD,CAArC;QACA,IAAM6D,WAAW,GAAGL,UAAU,CAACM,OAA/B;QACAxD,OAAO,GAAG,IAAV,CAHyC,CAKzC;;QACA,IAAMyD,cAAc,GAAGP,UAAU,CAACQ,KAAlC;;QACA,IAAID,cAAc,KAAK,KAAvB,EAA8B;UAC5B,IAAIN,YAAY,KAAKM,cAArB,EAAqC;YACnC;YACA1D,YAAY,GAAGwD,WAAf;UACD;QACF,CALD,MAKO,IAAIL,UAAU,CAACS,QAAX,KAAwB,IAA5B,EAAkC;UACvC1F,KAAK,GAAIsF,WAA2B,CAACK,IAA5B,CACPnD,OADO,EAEPG,MAFO,EAGPK,aAHO,EAIPK,MAJO,CAAT;;UAMA,IAAIrD,KAAK,KAAK,IAAd,EAAoB;YAClB8B,YAAY,GAAG9B,KAAK,CAAC,CAAD,CAApB;;YACA,IAAKA,KAAoC,CAAC+B,OAArC,KAAiDoB,SAAtD,EAAiE;cAC/DpB,OAAO,GAAI/B,KAAoC,CAAC+B,OAAhD;YACD;UACF,CALD,MAKO;YACLD,YAAY,GAAG,IAAf;UACD;QACF,CAfM,MAeA;UACL,KAAK5B,eAAL,CAAqBoF,WAArB,EAA4C3C,MAA5C;UACAb,YAAY,GAAG,KAAK9B,KAAL,CAAWsF,WAAX,EAAkChE,IAAlC,EAAwCqB,MAAxC,CAAf;QACD;;QAED,IAAIb,YAAY,KAAK,IAArB,EAA2B;UACzB;UACA;UACAD,SAAS,GAAGoD,UAAU,CAACpD,SAAvB;;UACA,IAAIA,SAAS,KAAKsB,SAAlB,EAA6B;YAC3B;YACA;YACA,IAAMyC,eAAe,GAAG/D,SAAS,CAACa,MAAlC;;YACA,KAAKf,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAGiE,eAAhB,EAAiCjE,CAAC,EAAlC,EAAsC;cACpC,IAAMkE,eAAe,GAAG1G,kBAAkB,CAAC0C,SAAS,CAACF,CAAD,CAAV,CAA1C;cACA,IAAMmE,gBAAgB,GAAGD,eAAe,CAACN,OAAzC;cACAvD,UAAU,GAAG,IAAb,CAHoC,CAKpC;cACA;;cACA,IAAI6D,eAAe,CAACH,QAAhB,KAA6B,IAAjC,EAAuC;gBACrC1F,KAAK,GAAI8F,gBAAgC,CAACH,IAAjC,CACPnD,OADO,EAEPG,MAFO,EAGPK,aAHO,EAIPK,MAJO,CAAT;;gBAMA,IAAIrD,KAAK,KAAK,IAAd,EAAoB;kBAClB4B,aAAa,GAAG5B,KAAK,CAAC,CAAD,CAArB;;kBACA,IACGA,KAAoC,CAAC+B,OAArC,KAAiDoB,SADpD,EAEE;oBACAnB,UAAU,GAAIhC,KAAoC,CAAC+B,OAAnD;kBACD;gBACF,CAPD,MAOO;kBACLH,aAAa,GAAG,IAAhB;gBACD;cACF,CAjBD,MAiBO;gBACL,KAAK1B,eAAL,CAAqB4F,gBAArB,EAAiDnD,MAAjD;gBACAf,aAAa,GAAG,KAAK5B,KAAL,CACd8F,gBADc,EAEdxE,IAFc,EAGdqB,MAHc,CAAhB;cAKD;;cAED,IAAIf,aAAa,IAAIA,aAAa,CAACc,MAAd,GAAuBZ,YAAY,CAACY,MAAzD,EAAiE;gBAC/DZ,YAAY,GAAGF,aAAf;gBACAG,OAAO,GAAGC,UAAV;gBACAiD,UAAU,GAAGY,eAAb,CAH+D,CAI/D;gBACA;;gBACA;cACD;YACF;UACF;;UACD;QACD;MACF,CA5FwB,CA8FzB;;;MACA,IAAI/D,YAAY,KAAK,IAArB,EAA2B;QACzBG,WAAW,GAAGH,YAAY,CAACY,MAA3B;QACAR,KAAK,GAAG+C,UAAU,CAAC/C,KAAnB;;QACA,IAAIA,KAAK,KAAKiB,SAAd,EAAyB;UACvBhB,OAAO,GAAG8C,UAAU,CAACc,YAArB,CADuB,CAEvB;UACA;;UACA3D,QAAQ,GAAG,KAAK5B,mBAAL,CACTsB,YADS,EAETa,MAFS,EAGTR,OAHS,EAIT8C,UAAU,CAACb,SAJF,EAKTlB,IALS,EAMTE,MANS,EAOTnB,WAPS,CAAX;UAUA,KAAKnB,aAAL,CAAmBsB,QAAnB,EAA6BL,OAA7B,EAduB,CAgBvB;;UACA,IAAIG,KAAK,KAAK,KAAd,EAAqB;YACnBU,kBAAkB,GAAG,KAAKhC,QAAL,CACnBoC,aADmB,EAEnBJ,kBAFmB,EAGnBR,QAHmB,CAArB;UAKD,CAND,MAMO;YACLiB,MAAM,CAACnB,KAAD,CAAN,CAAclD,IAAd,CAAmBoD,QAAnB;UACD;QACF;;QACDd,IAAI,GAAG,KAAKxB,SAAL,CAAewB,IAAf,EAAqBW,WAArB,CAAP;QACAU,MAAM,GAAGA,MAAM,GAAGV,WAAlB,CA/ByB,CAiCzB;;QACAmB,MAAM,GAAG,KAAK9C,gBAAL,CAAsB8C,MAAtB,EAA+BnB,WAA/B,CAAT;;QAEA,IAAIqB,UAAU,KAAK,IAAf,IAAuB2B,UAAU,CAACe,iBAAX,KAAiC,IAA5D,EAAkE;UAChE,IAAIC,eAAe,GAAG,CAAtB;UACA,IAAIC,eAAe,SAAnB;UACA,IAAIC,eAAe,SAAnB;UACA5C,qBAAqB,CAAC6C,SAAtB,GAAkC,CAAlC;;UACA,GAAG;YACDF,eAAe,GAAG3C,qBAAqB,CAACnF,IAAtB,CAA2B0D,YAA3B,CAAlB;;YACA,IAAIoE,eAAe,KAAK,IAAxB,EAA8B;cAC5BC,eAAe,GAAG5C,qBAAqB,CAAC6C,SAAtB,GAAkC,CAApD;cACAH,eAAe;YAChB;UACF,CAND,QAMSC,eAAe,KAAK,IAN7B;;UAQA,IAAID,eAAe,KAAK,CAAxB,EAA2B;YACzB/C,IAAI,GAAGA,IAAK,GAAG+C,eAAf;YACA7C,MAAM,GAAGnB,WAAW,GAAGkE,eAAvB;YACA,KAAK5F,gCAAL,CACE6B,QADF,EAEEF,KAFF,EAGEiE,eAHF,EAIEF,eAJF,EAKE/C,IALF,EAMEE,MANF,EAOEnB,WAPF;UASD;QACF,CA9DwB,CA+DzB;;;QACA,KAAK5B,WAAL,CAAiB4E,UAAjB,EAA6Bf,QAA7B,EAAuCa,SAAvC,EAAkD3C,QAAlD;MACD,CAjED,MAiEO;QACL;QACA,IAAMiE,gBAAgB,GAAG1D,MAAzB;QACA,IAAM2D,SAAS,GAAGpD,IAAlB;QACA,IAAMqD,WAAW,GAAGnD,MAApB;QACA,IAAIoD,gBAAgB,GAAG,KAAvB;;QACA,OAAO,CAACA,gBAAD,IAAqB7D,MAAM,GAAGF,SAArC,EAAgD;UAC9C;UACAH,WAAW,GAAGE,OAAO,CAAC2C,UAAR,CAAmBxC,MAAnB,CAAd,CAF8C,CAG9C;;UACArB,IAAI,GAAG,KAAKxB,SAAL,CAAewB,IAAf,EAAqB,CAArB,CAAP;UACAqB,MAAM;;UACN,KAAKjB,CAAC,GAAG,CAAT,EAAYA,CAAC,GAAG8B,sBAAhB,EAAwC9B,CAAC,EAAzC,EAA6C;YAC3C,IAAM+E,YAAU,GAAGtH,kBAAkB,CAACuC,CAAD,CAArC;YACA,IAAM4D,WAAW,GAAGmB,YAAU,CAAClB,OAA/B,CAF2C,CAI3C;;YACA,IAAMC,cAAc,GAAGiB,YAAU,CAAChB,KAAlC;;YACA,IAAID,cAAc,KAAK,KAAvB,EAA8B;cAC5B,IAAIhD,OAAO,CAAC2C,UAAR,CAAmBxC,MAAnB,MAA+B6C,cAAnC,EAAmD;gBACjD;gBACAgB,gBAAgB,GAAG,IAAnB;cACD;YACF,CALD,MAKO,IAAIC,YAAU,CAACf,QAAX,KAAwB,IAA5B,EAAkC;cACvCc,gBAAgB,GACblB,WAA2B,CAACK,IAA5B,CACCnD,OADD,EAECG,MAFD,EAGCK,aAHD,EAICK,MAJD,MAKK,IANR;YAOD,CARM,MAQA;cACL,KAAKnD,eAAL,CAAqBoF,WAArB,EAA4C3C,MAA5C;cACA6D,gBAAgB,GAAIlB,WAAsB,CAACK,IAAvB,CAA4BrE,IAA5B,MAAsC,IAA1D;YACD;;YAED,IAAIkF,gBAAgB,KAAK,IAAzB,EAA+B;cAC7B;YACD;UACF;QACF;;QAEDnE,SAAS,GAAGM,MAAM,GAAG0D,gBAArB,CA1CK,CA2CL;;QACA9D,GAAG,GAAG,KAAK3F,MAAL,CAAYP,oBAAZ,CAAiCqK,gCAAjC,CACJlE,OADI,EAEJ6D,gBAFI,EAGJhE,SAHI,EAIJiE,SAJI,EAKJC,WALI,CAAN;QAOAtD,MAAM,CAACjE,IAAP,CAAY;UACV2D,MAAM,EAAE0D,gBADE;UAEVnD,IAAI,EAAEoD,SAFI;UAGVlD,MAAM,EAAEmD,WAHE;UAIV7D,MAAM,EAAEL,SAJE;UAKV1C,OAAO,EAAE4C;QALC,CAAZ;MAOD;IACF,CA3VuD,CA6VxD;IACA;;;IACA,IAAI,CAAC,KAAKjD,SAAV,EAAqB;MACnB;MACA0D,aAAa,CAACN,MAAd,GAAuBE,kBAAvB;IACD;;IAED,OAAO;MACL+D,MAAM,EAAE3D,aADH;MAELK,MAAM,EAAEA,MAFH;MAGLJ,MAAM,EAAEA;IAHH,CAAP;EAKD,CAzWO;;EA2WA5B,8BAAR,UACEzE,MADF,EAEEsH,QAFF,EAGEa,SAHF,EAIE3C,QAJF,EAIkB;IAEhB,IAAIxF,MAAM,CAACgI,GAAP,KAAe,IAAnB,EAAyB;MACvB;MACA;MACA,IAAMgC,QAAQ,GAAGhK,MAAM,CAACoC,IAAxB;MACAkF,QAAQ,CAAC9B,QAAD,CAAR;;MACA,IAAIwE,QAAQ,KAAKzD,SAAjB,EAA4B;QAC1B4B,SAAS,CAACC,IAAV,CAAe,IAAf,EAAqB4B,QAArB;MACD;IACF,CARD,MAQO,IAAIhK,MAAM,CAACoC,IAAP,KAAgBmE,SAApB,EAA+B;MACpC4B,SAAS,CAACC,IAAV,CAAe,IAAf,EAAqBpI,MAAM,CAACoC,IAA5B;IACD;EACF,CAjBO;;EAmBAqC,4BAAR,UAAkBC,IAAlB,EAAgCoB,MAAhC,EAA8C;IAC5C,OAAOpB,IAAI,CAACuF,SAAL,CAAenE,MAAf,CAAP;EACD,CAFO;;EAIArB,kCAAR,UAAwByF,MAAxB,EAAwCC,YAAxC,EAA4D;IAC1DD,MAAM,CAACV,SAAP,GAAmBW,YAAnB;EACD,CAFO,CA3rBV,CA+rBE;;;EACQ1F,mDAAR,UACEe,QADF,EAEEF,KAFF,EAGE8E,SAHF,EAIEf,eAJF,EAKE/C,IALF,EAMEE,MANF,EAOEnB,WAPF,EAOqB;IAEnB,IAAIgF,YAAJ,EAAkBC,gBAAlB;;IACA,IAAIhF,KAAK,KAAKiB,SAAd,EAAyB;MACvB;MACA8D,YAAY,GAAGD,SAAS,KAAK/E,WAAW,GAAG,CAA3C;MACAiF,gBAAgB,GAAGD,YAAY,GAAG,CAAC,CAAJ,GAAQ,CAAvC;;MACA,IAAI,EAAEhB,eAAe,KAAK,CAApB,IAAyBgB,YAAY,KAAK,IAA5C,CAAJ,EAAuD;QACrD;QACA7E,QAAQ,CAAC+E,OAAT,GAAmBjE,IAAI,GAAGgE,gBAA1B,CAFqD,CAGrD;QACA;;QACA9E,QAAQ,CAACgF,SAAT,GAAqBhE,MAAM,GAAG,CAAT,GAAa,CAAC8D,gBAAnC;MACD,CAVsB,CAWvB;;IACD;EACF,CAvBO;;EAyBA7F,mCAAR,UAAyBgG,SAAzB,EAA4CpF,WAA5C,EAA+D;IAC7D,OAAOoF,SAAS,GAAGpF,WAAnB;EACD,CAFO;;EAQAZ,wCAAR,UACEsD,KADF,EAEEH,WAFF,EAGEuB,YAHF,EAIE3B,SAJF,EAIsB;IAEpB,OAAO;MACLO,KAAK,OADA;MAELH,WAAW,aAFN;MAGLuB,YAAY,cAHP;MAIL3B,SAAS;IAJJ,CAAP;EAMD,CAZO;;EAcA/C,uCAAR,UACEsD,KADF,EAEEH,WAFF,EAGEuB,YAHF,EAIE3B,SAJF,EAKEK,SALF,EAMEC,WANF,EAMqB;IAEnB,OAAO;MACLC,KAAK,OADA;MAELH,WAAW,aAFN;MAGLC,SAAS,WAHJ;MAILC,WAAW,aAJN;MAKLqB,YAAY,cALP;MAML3B,SAAS;IANJ,CAAP;EAQD,CAhBO;;EAkBA/C,kCAAR,UACEsD,KADF,EAEEH,WAFF,EAGEuB,YAHF,EAIE3B,SAJF,EAKEK,SALF,EAMEC,WANF,EAOEzC,WAPF,EAOqB;IAEnB,OAAO;MACL0C,KAAK,OADA;MAELH,WAAW,aAFN;MAGL8C,SAAS,EAAE9C,WAAW,GAAGvC,WAAd,GAA4B,CAHlC;MAILwC,SAAS,WAJJ;MAKL0C,OAAO,EAAE1C,SALJ;MAMLC,WAAW,aANN;MAOL0C,SAAS,EAAE1C,WAAW,GAAGzC,WAAd,GAA4B,CAPlC;MAQL8D,YAAY,cARP;MASL3B,SAAS;IATJ,CAAP;EAWD,CApBO;;EA8BA/C,oCAAR,UACEkG,WADF,EAEEC,KAFF,EAGEC,UAHF,EAGoB;IAElBF,WAAW,CAACvI,IAAZ,CAAiByI,UAAjB;IACA,OAAOD,KAAP;EACD,CAPO;;EASAnG,4CAAR,UACEkG,WADF,EAEEC,KAFF,EAGEC,UAHF,EAGoB;IAElBF,WAAW,CAACC,KAAD,CAAX,GAAqBC,UAArB;IACAD,KAAK;IACL,OAAOA,KAAP;EACD,CARO;;EAaAnG,wCAAR,UAA8BqG,KAA9B,EAA6C3F,OAA7C,EAAyD,CAAU,CAA3D;;EAEAV,0CAAR,UAAgCqG,KAAhC,EAA+C3F,OAA/C,EAA2D;IACzD,IAAIA,OAAO,KAAK,IAAhB,EAAsB;MACpB2F,KAAK,CAAC3F,OAAN,GAAgBA,OAAhB;IACD;EACF,CAJO;;EAaAV,gCAAR,UACEkE,OADF,EAEEjE,IAFF,EAGEqB,MAHF,EAGgB;IAEd,IAAMgF,KAAK,GAAGpC,OAAO,CAACnH,IAAR,CAAakD,IAAb,CAAd;;IACA,IAAIqG,KAAK,KAAK,IAAd,EAAoB;MAClB,OAAOrG,IAAI,CAACuF,SAAL,CAAelE,MAAf,EAAuB4C,OAAO,CAACa,SAA/B,CAAP;IACD;;IACD,OAAO,IAAP;EACD,CAVO;;EAYA/E,gCAAR,UAAsBkE,OAAtB,EAAuCjE,IAAvC,EAAmD;IACjD,IAAMsG,WAAW,GAAGrC,OAAO,CAACI,IAAR,CAAarE,IAAb,CAApB;IACA,OAAOsG,WAAW,KAAK,IAAhB,GAAuBA,WAAW,CAAC,CAAD,CAAlC,GAAwC,IAA/C;EACD,CAHO;;EA/0BMvG,gBACZ,oFACA,6GAFY;EAIAA,WAAK,gBAAL;EAu2BhB;AAAC,CA52BD;;AAAaxF","names":["LexerDefinitionErrorType","exports","DEFAULT_LEXER_CONFIG","deferDefinitionErrorsHandling","positionTracking","lineTerminatorsPattern","lineTerminatorCharacters","ensureOptimizations","safeMode","errorMessageProvider","lexer_errors_public_1","traceInitPerf","skipValidations","Object","freeze","lexerDefinition","config","phaseDesc","phaseImpl","_this","traceInitIndent","indent","Array","join","traceInitMaxIdent","console","log","concat","time","value","traceMethod","warn","Error","traceInitVal","Infinity","TRACE_INIT","actualDefinition","hasOnlySingleMode","lexer_1","trackStartLines","test","trackEndLines","modes","defaultMode","lexerDefinitionErrors","lexerDefinitionWarning","currModeValue","currModeName","currTokType","allModeNames","currModDef","currModName","push","currAnalyzeResult_1","tracer","patternIdxToConfig","charCodeToPatternIdxToConfig","emptyGroups","hasCustom","canModeBeOptimized","canBeOptimized","allErrMessages","error","message","allErrMessagesString","warningDescriptor","chopInput","identity_1","match","matchWithTest","updateLastIndex","noop_1","matchWithExec","handleModes","computeNewColumn","updateTokenEndLineColumnLocation","createTokenInstance","createFullToken","createStartOnlyToken","createOffsetOnlyToken","addToken","addTokenUsingPush","handlePayload","handlePayloadWithCustom","addTokenUsingMemberAccess","handlePayloadNoCustom","unOptimizedModes","cannotBeOptimized","modeName","Lexer","text","initialMode","tokenizeInternal","i","j","k","matchAltImage","longerAlt","matchedImage","payload","altPayload","imageLength","group","tokType","newToken","errLength","droppedChar","msg","orgText","orgLength","length","offset","matchedTokensIndex","guessedNumberOfTokens","Math","floor","matchedTokens","errors","line","undefined","column","groups","trackLines","lineTerminatorPattern","currModePatternsLength","currCharCodeToPatternIdxToConfig","modeStack","emptyArray","getPossiblePatterns","getPossiblePatternsSlow","getPossiblePatternsOptimized","charCode","optimizedCharIdx","possiblePatterns","pop_mode","popToken","tokenType","PUSH_MODE","msg_1","buildUnableToPopLexerModeMessage","startOffset","startLine","startColumn","image","pop","newMode","modeCanBeOptimized","push_mode","call","currConfig","nextCharCode","charCodeAt","chosenPatternIdxToConfig","chosenPatternsLength","currPattern","pattern","singleCharCode","short","isCustom","exec","longerAltLength","longerAltConfig","longerAltPattern","tokenTypeIdx","canLineTerminator","numOfLTsInMatch","foundTerminator","lastLTEndOffset","lastIndex","errorStartOffset","errorLine","errorColumn","foundResyncPoint","currConfig_1","buildUnexpectedCharactersMessage","tokens","pushMode","substring","regExp","newLastIndex","lastLTIdx","lastCharIsLT","fixForEndingInLT","endLine","endColumn","oldColumn","endOffset","tokenVector","index","tokenToAdd","token","found","regExpArray"],"sources":["D:\\Jord\\l4fycy\\node_modules\\chevrotain\\src\\scan\\lexer_public.ts"],"sourcesContent":["import {\n  analyzeTokenTypes,\n  charCodeToOptimizedIndex,\n  cloneEmptyGroups,\n  DEFAULT_MODE,\n  IAnalyzeResult,\n  IPatternConfig,\n  LineTerminatorOptimizedTester,\n  performRuntimeChecks,\n  performWarningRuntimeChecks,\n  SUPPORT_STICKY,\n  validatePatterns\n} from \"./lexer\"\nimport noop from \"lodash/noop\"\nimport isEmpty from \"lodash/isEmpty\"\nimport isArray from \"lodash/isArray\"\nimport last from \"lodash/last\"\nimport reject from \"lodash/reject\"\nimport map from \"lodash/map\"\nimport forEach from \"lodash/forEach\"\nimport keys from \"lodash/keys\"\nimport isUndefined from \"lodash/isUndefined\"\nimport identity from \"lodash/identity\"\nimport assign from \"lodash/assign\"\nimport reduce from \"lodash/reduce\"\nimport clone from \"lodash/clone\"\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\"\nimport { augmentTokenTypes } from \"./tokens\"\nimport {\n  CustomPatternMatcherFunc,\n  CustomPatternMatcherReturn,\n  ILexerConfig,\n  ILexerDefinitionError,\n  ILexingError,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType\n} from \"@chevrotain/types\"\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public\"\nimport { clearRegExpParserCache } from \"./reg_exp_parser\"\n\nexport interface ILexingResult {\n  tokens: IToken[]\n  groups: { [groupName: string]: IToken[] }\n  errors: ILexingError[]\n}\n\nexport enum LexerDefinitionErrorType {\n  MISSING_PATTERN,\n  INVALID_PATTERN,\n  EOI_ANCHOR_FOUND,\n  UNSUPPORTED_FLAGS_FOUND,\n  DUPLICATE_PATTERNS_FOUND,\n  INVALID_GROUP_TYPE_FOUND,\n  PUSH_MODE_DOES_NOT_EXIST,\n  MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n  MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n  MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n  LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n  SOI_ANCHOR_FOUND,\n  EMPTY_MATCH_PATTERN,\n  NO_LINE_BREAKS_FLAGS,\n  UNREACHABLE_PATTERN,\n  IDENTIFY_TERMINATOR,\n  CUSTOM_LINE_BREAK\n}\n\nexport interface IRegExpExec {\n  exec: CustomPatternMatcherFunc\n}\n\nconst DEFAULT_LEXER_CONFIG: Required<ILexerConfig> = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false\n}\n\nObject.freeze(DEFAULT_LEXER_CONFIG)\n\nexport class Lexer {\n  public static SKIPPED =\n    \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\"\n\n  public static NA = /NOT_APPLICABLE/\n  public lexerDefinitionErrors: ILexerDefinitionError[] = []\n  public lexerDefinitionWarning: ILexerDefinitionError[] = []\n\n  protected patternIdxToConfig: Record<string, IPatternConfig[]> = {}\n  protected charCodeToPatternIdxToConfig: {\n    [modeName: string]: { [charCode: number]: IPatternConfig[] }\n  } = {}\n\n  protected modes: string[] = []\n  protected defaultMode!: string\n  protected emptyGroups: { [groupName: string]: IToken } = {}\n\n  private config: Required<ILexerConfig>\n  private trackStartLines: boolean = true\n  private trackEndLines: boolean = true\n  private hasCustom: boolean = false\n  private canModeBeOptimized: Record<string, boolean> = {}\n\n  private traceInitPerf!: boolean | number\n  private traceInitMaxIdent!: number\n  private traceInitIndent: number\n\n  constructor(\n    protected lexerDefinition: TokenType[] | IMultiModeLexerDefinition,\n    config: ILexerConfig = DEFAULT_LEXER_CONFIG\n  ) {\n    if (typeof config === \"boolean\") {\n      throw Error(\n        \"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n          \"a boolean 2nd argument is no longer supported\"\n      )\n    }\n\n    // todo: defaults func?\n    this.config = assign({}, DEFAULT_LEXER_CONFIG, config) as any\n\n    const traceInitVal = this.config.traceInitPerf\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity\n      this.traceInitPerf = true\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal\n      this.traceInitPerf = true\n    }\n    this.traceInitIndent = -1\n\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition!: IMultiModeLexerDefinition\n      let hasOnlySingleMode = true\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (\n          this.config.lineTerminatorsPattern ===\n          DEFAULT_LEXER_CONFIG.lineTerminatorsPattern\n        ) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester\n        } else {\n          if (\n            this.config.lineTerminatorCharacters ===\n            DEFAULT_LEXER_CONFIG.lineTerminatorCharacters\n          ) {\n            throw Error(\n              \"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\"\n            )\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error(\n            '\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.'\n          )\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(\n          this.config.positionTracking\n        )\n        this.trackEndLines = /full/i.test(this.config.positionTracking)\n\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (isArray(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone(lexerDefinition) },\n            defaultMode: DEFAULT_MODE\n          }\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false\n          actualDefinition = clone(<IMultiModeLexerDefinition>lexerDefinition)\n        }\n      })\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n            performRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters\n            )\n          )\n        })\n\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(\n            performWarningRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters\n            )\n          )\n        })\n      }\n\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes\n        ? actualDefinition.modes\n        : {}\n\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject<TokenType>(\n          currModeValue,\n          (currTokType) => isUndefined(currTokType)\n        )\n      })\n\n      const allModeNames = keys(actualDefinition.modes)\n\n      forEach(\n        actualDefinition.modes,\n        (currModDef: TokenType[], currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName)\n\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n                  validatePatterns(currModDef, allModeNames)\n                )\n              })\n            }\n\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef)\n\n              let currAnalyzeResult!: IAnalyzeResult\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters:\n                    this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT\n                })\n              })\n\n              this.patternIdxToConfig[currModName] =\n                currAnalyzeResult.patternIdxToConfig\n\n              this.charCodeToPatternIdxToConfig[currModName] =\n                currAnalyzeResult.charCodeToPatternIdxToConfig\n\n              this.emptyGroups = assign(\n                {},\n                this.emptyGroups,\n                currAnalyzeResult.emptyGroups\n              ) as any\n\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom\n\n              this.canModeBeOptimized[currModName] =\n                currAnalyzeResult.canBeOptimized\n            }\n          })\n        }\n      )\n\n      this.defaultMode = actualDefinition.defaultMode\n\n      if (\n        !isEmpty(this.lexerDefinitionErrors) &&\n        !this.config.deferDefinitionErrorsHandling\n      ) {\n        const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n          return error.message\n        })\n        const allErrMessagesString = allErrMessages.join(\n          \"-----------------------\\n\"\n        )\n        throw new Error(\n          \"Errors detected in definition of Lexer:\\n\" + allErrMessagesString\n        )\n      }\n\n      // Only print warning if there are no errors, This will avoid pl\n      forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message)\n      })\n\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (SUPPORT_STICKY) {\n          this.chopInput = <any>identity\n          this.match = this.matchWithTest\n        } else {\n          this.updateLastIndex = noop\n          this.match = this.matchWithExec\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken\n        } else {\n          throw Error(\n            `Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`\n          )\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush\n          this.handlePayload = this.handlePayloadWithCustom\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess\n          this.handlePayload = this.handlePayloadNoCustom\n        }\n      })\n\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce(\n          this.canModeBeOptimized,\n          (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName)\n            }\n            return cannotBeOptimized\n          },\n          [] as string[]\n        )\n\n        if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n          throw Error(\n            `Lexer Modes: < ${unOptimizedModes.join(\n              \", \"\n            )} > cannot be optimized.\\n` +\n              '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n              \"\\t Or inspect the console log for details on how to resolve these issues.\"\n          )\n        }\n      })\n\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache()\n      })\n\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this)\n      })\n    })\n  }\n\n  public tokenize(\n    text: string,\n    initialMode: string = this.defaultMode\n  ): ILexingResult {\n    if (!isEmpty(this.lexerDefinitionErrors)) {\n      const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n        return error.message\n      })\n      const allErrMessagesString = allErrMessages.join(\n        \"-----------------------\\n\"\n      )\n      throw new Error(\n        \"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n          allErrMessagesString\n      )\n    }\n\n    return this.tokenizeInternal(text, initialMode)\n  }\n\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  private tokenizeInternal(text: string, initialMode: string): ILexingResult {\n    let i,\n      j,\n      k,\n      matchAltImage,\n      longerAlt,\n      matchedImage: string | null,\n      payload,\n      altPayload,\n      imageLength,\n      group,\n      tokType,\n      newToken: IToken,\n      errLength,\n      droppedChar,\n      msg,\n      match\n    const orgText = text\n    const orgLength = orgText.length\n    let offset = 0\n    let matchedTokensIndex = 0\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    const guessedNumberOfTokens = this.hasCustom\n      ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n      : Math.floor(text.length / 10)\n    const matchedTokens = new Array(guessedNumberOfTokens)\n    const errors: ILexingError[] = []\n    let line = this.trackStartLines ? 1 : undefined\n    let column = this.trackStartLines ? 1 : undefined\n    const groups: any = cloneEmptyGroups(this.emptyGroups)\n    const trackLines = this.trackStartLines\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern\n\n    let currModePatternsLength = 0\n    let patternIdxToConfig: IPatternConfig[] = []\n    let currCharCodeToPatternIdxToConfig: {\n      [charCode: number]: IPatternConfig[]\n    } = []\n\n    const modeStack: string[] = []\n\n    const emptyArray: IPatternConfig[] = []\n    Object.freeze(emptyArray)\n    let getPossiblePatterns!: (charCode: number) => IPatternConfig[]\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig\n    }\n\n    function getPossiblePatternsOptimized(charCode: number): IPatternConfig[] {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode)\n      const possiblePatterns =\n        currCharCodeToPatternIdxToConfig[optimizedCharIdx]\n      if (possiblePatterns === undefined) {\n        return emptyArray\n      } else {\n        return possiblePatterns\n      }\n    }\n\n    const pop_mode = (popToken: IToken) => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (\n        modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === undefined\n      ) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg =\n          this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(\n            popToken\n          )\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg\n        })\n      } else {\n        modeStack.pop()\n        const newMode = last(modeStack)!\n        patternIdxToConfig = this.patternIdxToConfig[newMode]\n        currCharCodeToPatternIdxToConfig =\n          this.charCodeToPatternIdxToConfig[newMode]\n        currModePatternsLength = patternIdxToConfig.length\n        const modeCanBeOptimized =\n          this.canModeBeOptimized[newMode] && this.config.safeMode === false\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow\n        }\n      }\n    }\n\n    function push_mode(this: Lexer, newMode: string) {\n      modeStack.push(newMode)\n      currCharCodeToPatternIdxToConfig =\n        this.charCodeToPatternIdxToConfig[newMode]\n\n      patternIdxToConfig = this.patternIdxToConfig[newMode]\n      currModePatternsLength = patternIdxToConfig.length\n\n      currModePatternsLength = patternIdxToConfig.length\n      const modeCanBeOptimized =\n        this.canModeBeOptimized[newMode] && this.config.safeMode === false\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow\n      }\n    }\n\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode)\n\n    let currConfig!: IPatternConfig\n\n    while (offset < orgLength) {\n      matchedImage = null\n\n      const nextCharCode = orgText.charCodeAt(offset)\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode)\n      const chosenPatternsLength = chosenPatternIdxToConfig.length\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i]\n        const currPattern = currConfig.pattern\n        payload = null\n\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        const singleCharCode = currConfig.short\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern as string\n          }\n        } else if (currConfig.isCustom === true) {\n          match = (currPattern as IRegExpExec).exec(\n            orgText,\n            offset,\n            matchedTokens,\n            groups\n          )\n          if (match !== null) {\n            matchedImage = match[0]\n            if ((match as CustomPatternMatcherReturn).payload !== undefined) {\n              payload = (match as CustomPatternMatcherReturn).payload\n            }\n          } else {\n            matchedImage = null\n          }\n        } else {\n          this.updateLastIndex(currPattern as RegExp, offset)\n          matchedImage = this.match(currPattern as RegExp, text, offset)\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]]\n              const longerAltPattern = longerAltConfig.pattern\n              altPayload = null\n\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = (longerAltPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups\n                )\n                if (match !== null) {\n                  matchAltImage = match[0]\n                  if (\n                    (match as CustomPatternMatcherReturn).payload !== undefined\n                  ) {\n                    altPayload = (match as CustomPatternMatcherReturn).payload\n                  }\n                } else {\n                  matchAltImage = null\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern as RegExp, offset)\n                matchAltImage = this.match(\n                  longerAltPattern as RegExp,\n                  text,\n                  offset\n                )\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage\n                payload = altPayload\n                currConfig = longerAltConfig\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break\n              }\n            }\n          }\n          break\n        }\n      }\n\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length\n        group = currConfig.group\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(\n            matchedImage,\n            offset,\n            tokType,\n            currConfig.tokenType,\n            line,\n            column,\n            imageLength\n          )\n\n          this.handlePayload(newToken, payload)\n\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(\n              matchedTokens,\n              matchedTokensIndex,\n              newToken\n            )\n          } else {\n            groups[group].push(newToken)\n          }\n        }\n        text = this.chopInput(text, imageLength)\n        offset = offset + imageLength\n\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column!, imageLength)\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0\n          let foundTerminator\n          let lastLTEndOffset: number\n          lineTerminatorPattern.lastIndex = 0\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage)\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1\n              numOfLTsInMatch++\n            }\n          } while (foundTerminator === true)\n\n          if (numOfLTsInMatch !== 0) {\n            line = line! + numOfLTsInMatch\n            column = imageLength - lastLTEndOffset!\n            this.updateTokenEndLineColumnLocation(\n              newToken!,\n              group!,\n              lastLTEndOffset!,\n              numOfLTsInMatch,\n              line,\n              column,\n              imageLength\n            )\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken!)\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset\n        const errorLine = line\n        const errorColumn = column\n        let foundResyncPoint = false\n        while (!foundResyncPoint && offset < orgLength) {\n          // drop chars until we succeed in matching something\n          droppedChar = orgText.charCodeAt(offset)\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1)\n          offset++\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j]\n            const currPattern = currConfig.pattern\n\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            const singleCharCode = currConfig.short\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint =\n                (currPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups\n                ) !== null\n            } else {\n              this.updateLastIndex(currPattern as RegExp, offset)\n              foundResyncPoint = (currPattern as RegExp).exec(text) !== null\n            }\n\n            if (foundResyncPoint === true) {\n              break\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(\n          orgText,\n          errorStartOffset,\n          errLength,\n          errorLine,\n          errorColumn\n        )\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        })\n      }\n    }\n\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors\n    }\n  }\n\n  private handleModes(\n    config: IPatternConfig,\n    pop_mode: (tok: IToken) => void,\n    push_mode: (this: Lexer, pushMode: string) => void,\n    newToken: IToken\n  ) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push\n      pop_mode(newToken)\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode)\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push)\n    }\n  }\n\n  private chopInput(text: string, length: number): string {\n    return text.substring(length)\n  }\n\n  private updateLastIndex(regExp: RegExp, newLastIndex: number): void {\n    regExp.lastIndex = newLastIndex\n  }\n\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  private updateTokenEndLineColumnLocation(\n    newToken: IToken,\n    group: string | false,\n    lastLTIdx: number,\n    numOfLTsInMatch: number,\n    line: number,\n    column: number,\n    imageLength: number\n  ): void {\n    let lastCharIsLT, fixForEndingInLT\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1\n      fixForEndingInLT = lastCharIsLT ? -1 : 0\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  }\n\n  private computeNewColumn(oldColumn: number, imageLength: number) {\n    return oldColumn + imageLength\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private createTokenInstance!: (...args: any[]) => IToken\n\n  private createOffsetOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType\n  ) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType\n    }\n  }\n\n  private createStartOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number\n  ) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType\n    }\n  }\n\n  private createFullToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n    imageLength: number\n  ): IToken {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType\n    }\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private addToken!: (\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken\n  ) => number\n\n  private addTokenUsingPush(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken\n  ): number {\n    tokenVector.push(tokenToAdd)\n    return index\n  }\n\n  private addTokenUsingMemberAccess(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken\n  ): number {\n    tokenVector[index] = tokenToAdd\n    index++\n    return index\n  }\n\n  // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n  private handlePayload: (token: IToken, payload: any) => void\n\n  private handlePayloadNoCustom(token: IToken, payload: any): void {}\n\n  private handlePayloadWithCustom(token: IToken, payload: any): void {\n    if (payload !== null) {\n      token.payload = payload\n    }\n  }\n\n  // place holder to be replaced with chosen alternative at runtime\n  private match!: (\n    pattern: RegExp,\n    text: string,\n    offset: number\n  ) => string | null\n\n  private matchWithTest(\n    pattern: RegExp,\n    text: string,\n    offset: number\n  ): string | null {\n    const found = pattern.test(text)\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex)\n    }\n    return null\n  }\n\n  private matchWithExec(pattern: RegExp, text: string): string | null {\n    const regExpArray = pattern.exec(text)\n    return regExpArray !== null ? regExpArray[0] : null\n  }\n\n  // Duplicated from the parser's perf trace trait to allow future extraction\n  // of the lexer to a separate package.\n  TRACE_INIT = <T>(phaseDesc: string, phaseImpl: () => T): T => {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\")\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`)\n      }\n      const { time, value } = timer(phaseImpl)\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`)\n      }\n      this.traceInitIndent--\n      return value\n    } else {\n      return phaseImpl()\n    }\n  }\n}\n"]},"metadata":{},"sourceType":"script"}