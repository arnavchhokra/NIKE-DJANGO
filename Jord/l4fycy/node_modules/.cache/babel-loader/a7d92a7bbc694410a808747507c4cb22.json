{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.LexerAdapter = void 0;\n\nvar parser_1 = require(\"../parser\");\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\n\n\nvar LexerAdapter =\n/** @class */\nfunction () {\n  function LexerAdapter() {}\n\n  LexerAdapter.prototype.initLexerAdapter = function () {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  };\n\n  Object.defineProperty(LexerAdapter.prototype, \"input\", {\n    get: function get() {\n      return this.tokVector;\n    },\n    set: function set(newInput) {\n      // @ts-ignore - `this parameter` not supported in setters/getters\n      //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n      if (this.selfAnalysisDone !== true) {\n        throw Error(\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\");\n      } // @ts-ignore - `this parameter` not supported in setters/getters\n      //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n\n\n      this.reset();\n      this.tokVector = newInput;\n      this.tokVectorLength = newInput.length;\n    },\n    enumerable: false,\n    configurable: true\n  }); // skips a token and returns the next token\n\n  LexerAdapter.prototype.SKIP_TOKEN = function () {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return parser_1.END_OF_FILE;\n    }\n  }; // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n\n\n  LexerAdapter.prototype.LA = function (howMuch) {\n    var soughtIdx = this.currIdx + howMuch;\n\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return parser_1.END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  };\n\n  LexerAdapter.prototype.consumeToken = function () {\n    this.currIdx++;\n  };\n\n  LexerAdapter.prototype.exportLexerState = function () {\n    return this.currIdx;\n  };\n\n  LexerAdapter.prototype.importLexerState = function (newState) {\n    this.currIdx = newState;\n  };\n\n  LexerAdapter.prototype.resetLexerState = function () {\n    this.currIdx = -1;\n  };\n\n  LexerAdapter.prototype.moveToTerminatedState = function () {\n    this.currIdx = this.tokVector.length - 1;\n  };\n\n  LexerAdapter.prototype.getLexerPosition = function () {\n    return this.exportLexerState();\n  };\n\n  return LexerAdapter;\n}();\n\nexports.LexerAdapter = LexerAdapter;","map":{"version":3,"mappings":";;;;;;;AAAA;AAIA;;;;;;;;;AAOA;AAAA;AAAA;EAAA,yBA0EC;;EArECA;IACE,KAAKC,SAAL,GAAiB,EAAjB;IACA,KAAKC,eAAL,GAAuB,CAAvB;IACA,KAAKC,OAAL,GAAe,CAAC,CAAhB;EACD,CAJD;;EAMAC,sBAAIJ,sBAAJ,EAAI,OAAJ,EAAS;SAeT;MACE,OAAO,KAAKC,SAAZ;IACD,CAjBQ;SAAT,aAAUI,QAAV,EAA4B;MAC1B;MACA;MACA,IAAI,KAAKC,gBAAL,KAA0B,IAA9B,EAAoC;QAClC,MAAMC,KAAK,CACT,kFADS,CAAX;MAGD,CAPyB,CAQ1B;MACA;;;MACA,KAAKC,KAAL;MACA,KAAKP,SAAL,GAAiBI,QAAjB;MACA,KAAKH,eAAL,GAAuBG,QAAQ,CAACI,MAAhC;IACD,CAbQ;qBAAA;;EAAA,CAAT,EAXF,CA8BE;;EACAT;IACE,IAAI,KAAKG,OAAL,IAAgB,KAAKF,SAAL,CAAeQ,MAAf,GAAwB,CAA5C,EAA+C;MAC7C,KAAKC,YAAL;MACA,OAAO,KAAKC,EAAL,CAAQ,CAAR,CAAP;IACD,CAHD,MAGO;MACL,OAAOC,oBAAP;IACD;EACF,CAPD,CA/BF,CAwCE;EACA;;;EACAZ,sCAAwBa,OAAxB,EAAuC;IACrC,IAAMC,SAAS,GAAG,KAAKX,OAAL,GAAeU,OAAjC;;IACA,IAAIC,SAAS,GAAG,CAAZ,IAAiB,KAAKZ,eAAL,IAAwBY,SAA7C,EAAwD;MACtD,OAAOF,oBAAP;IACD,CAFD,MAEO;MACL,OAAO,KAAKX,SAAL,CAAea,SAAf,CAAP;IACD;EACF,CAPD;;EASAd;IACE,KAAKG,OAAL;EACD,CAFD;;EAIAH;IACE,OAAO,KAAKG,OAAZ;EACD,CAFD;;EAIAH,oDAAsCe,QAAtC,EAAsD;IACpD,KAAKZ,OAAL,GAAeY,QAAf;EACD,CAFD;;EAIAf;IACE,KAAKG,OAAL,GAAe,CAAC,CAAhB;EACD,CAFD;;EAIAH;IACE,KAAKG,OAAL,GAAe,KAAKF,SAAL,CAAeQ,MAAf,GAAwB,CAAvC;EACD,CAFD;;EAIAT;IACE,OAAO,KAAKgB,gBAAL,EAAP;EACD,CAFD;;EAGF;AAAC,CA1ED;;AAAaC","names":["LexerAdapter","tokVector","tokVectorLength","currIdx","Object","newInput","selfAnalysisDone","Error","reset","length","consumeToken","LA","parser_1","howMuch","soughtIdx","newState","exportLexerState","exports"],"sources":["C:\\Users\\Arnav\\Downloads\\l4fycy\\node_modules\\chevrotain\\src\\parse\\parser\\traits\\lexer_adapter.ts"],"sourcesContent":["import { END_OF_FILE } from \"../parser\"\nimport { IToken } from \"@chevrotain/types\"\nimport { MixedInParser } from \"./parser_traits\"\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[]\n  tokVectorLength: number\n  currIdx: number\n\n  initLexerAdapter() {\n    this.tokVector = []\n    this.tokVectorLength = 0\n    this.currIdx = -1\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`\n      )\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset()\n    this.tokVector = newInput\n    this.tokVectorLength = newInput.length\n  }\n\n  get input(): IToken[] {\n    return this.tokVector\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken()\n      return this.LA(1)\n    } else {\n      return END_OF_FILE\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE\n    } else {\n      return this.tokVector[soughtIdx]\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState()\n  }\n}\n"]},"metadata":{},"sourceType":"script"}