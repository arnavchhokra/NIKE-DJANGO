{"ast":null,"code":"\"use strict\";\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n      }\n    };\n\n    return _extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n\n    _extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.attemptInRepetitionRecovery = exports.Recoverable = exports.InRuleRecoveryException = exports.IN_RULE_RECOVERY_EXCEPTION = exports.EOF_FOLLOW_KEY = void 0;\n\nvar tokens_public_1 = require(\"../../../scan/tokens_public\");\n\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\n\nvar dropRight_1 = __importDefault(require(\"lodash/dropRight\"));\n\nvar flatten_1 = __importDefault(require(\"lodash/flatten\"));\n\nvar map_1 = __importDefault(require(\"lodash/map\"));\n\nvar find_1 = __importDefault(require(\"lodash/find\"));\n\nvar has_1 = __importDefault(require(\"lodash/has\"));\n\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\n\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\n\nvar exceptions_public_1 = require(\"../../exceptions_public\");\n\nvar constants_1 = require(\"../../constants\");\n\nvar parser_1 = require(\"../parser\");\n\nexports.EOF_FOLLOW_KEY = {};\nexports.IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n\nvar InRuleRecoveryException =\n/** @class */\nfunction (_super) {\n  __extends(InRuleRecoveryException, _super);\n\n  function InRuleRecoveryException(message) {\n    var _this = _super.call(this, message) || this;\n\n    _this.name = exports.IN_RULE_RECOVERY_EXCEPTION;\n    return _this;\n  }\n\n  return InRuleRecoveryException;\n}(Error);\n\nexports.InRuleRecoveryException = InRuleRecoveryException;\n/**\r\n * This trait is responsible for the error recovery and fault tolerant logic\r\n */\n\nvar Recoverable =\n/** @class */\nfunction () {\n  function Recoverable() {}\n\n  Recoverable.prototype.initRecoverable = function (config) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n    this.recoveryEnabled = (0, has_1.default)(config, \"recoveryEnabled\") ? config.recoveryEnabled // assumes end user provides the correct config value/type\n    : parser_1.DEFAULT_PARSER_CONFIG.recoveryEnabled; // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  };\n\n  Recoverable.prototype.getTokenToInsert = function (tokType) {\n    var tokToInsert = (0, tokens_public_1.createTokenInstance)(tokType, \"\", NaN, NaN, NaN, NaN, NaN, NaN);\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  };\n\n  Recoverable.prototype.canTokenTypeBeInsertedInRecovery = function (tokType) {\n    return true;\n  };\n\n  Recoverable.prototype.canTokenTypeBeDeletedInRecovery = function (tokType) {\n    return true;\n  };\n\n  Recoverable.prototype.tryInRepetitionRecovery = function (grammarRule, grammarRuleArgs, lookAheadFunc, expectedTokType) {\n    var _this = this; // TODO: can the resyncTokenType be cached?\n\n\n    var reSyncTokType = this.findReSyncTokenType();\n    var savedLexerState = this.exportLexerState();\n    var resyncedTokens = [];\n    var passedResyncPoint = false;\n    var nextTokenWithoutResync = this.LA(1);\n    var currToken = this.LA(1);\n\n    var generateErrorMessage = function generateErrorMessage() {\n      var previousToken = _this.LA(0); // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n\n\n      var msg = _this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: _this.getCurrRuleFullName()\n      });\n\n      var error = new exceptions_public_1.MismatchedTokenException(msg, nextTokenWithoutResync, _this.LA(0)); // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n\n      error.resyncedTokens = (0, dropRight_1.default)(resyncedTokens);\n\n      _this.SAVE_ERROR(error);\n    };\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage(); // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    } // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n\n\n    this.importLexerState(savedLexerState);\n  };\n\n  Recoverable.prototype.shouldInRepetitionRecoveryBeTried = function (expectTokAfterLastMatch, nextTokIdx, notStuck) {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    } // no need to recover, next token is what we expect...\n\n\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    } // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n\n\n    if (this.isBackTracking()) {\n      return false;\n    } // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n\n\n    if (this.canPerformInRuleRecovery(expectTokAfterLastMatch, this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx))) {\n      return false;\n    }\n\n    return true;\n  }; // Error Recovery functionality\n\n\n  Recoverable.prototype.getFollowsForInRuleRecovery = function (tokType, tokIdxInRule) {\n    var grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    var follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  };\n\n  Recoverable.prototype.tryInRuleRecovery = function (expectedTokType, follows) {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      var tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      var nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  };\n\n  Recoverable.prototype.canPerformInRuleRecovery = function (expectedToken, follows) {\n    return this.canRecoverWithSingleTokenInsertion(expectedToken, follows) || this.canRecoverWithSingleTokenDeletion(expectedToken);\n  };\n\n  Recoverable.prototype.canRecoverWithSingleTokenInsertion = function (expectedTokType, follows) {\n    var _this = this;\n\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    } // must know the possible following tokens to perform single token insertion\n\n\n    if ((0, isEmpty_1.default)(follows)) {\n      return false;\n    }\n\n    var mismatchedTok = this.LA(1);\n    var isMisMatchedTokInFollows = (0, find_1.default)(follows, function (possibleFollowsTokType) {\n      return _this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n    }) !== undefined;\n    return isMisMatchedTokInFollows;\n  };\n\n  Recoverable.prototype.canRecoverWithSingleTokenDeletion = function (expectedTokType) {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    var isNextTokenWhatIsExpected = this.tokenMatcher(this.LA(2), expectedTokType);\n    return isNextTokenWhatIsExpected;\n  };\n\n  Recoverable.prototype.isInCurrentRuleReSyncSet = function (tokenTypeIdx) {\n    var followKey = this.getCurrFollowKey();\n    var currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return (0, includes_1.default)(currentRuleReSyncSet, tokenTypeIdx);\n  };\n\n  Recoverable.prototype.findReSyncTokenType = function () {\n    var allPossibleReSyncTokTypes = this.flattenFollowSet(); // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n\n    var nextToken = this.LA(1);\n    var k = 2;\n\n    while (true) {\n      var foundMatch = (0, find_1.default)(allPossibleReSyncTokTypes, function (resyncTokType) {\n        var canMatch = (0, tokens_public_1.tokenMatcher)(nextToken, resyncTokType);\n        return canMatch;\n      });\n\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n\n      nextToken = this.LA(k);\n      k++;\n    }\n  };\n\n  Recoverable.prototype.getCurrFollowKey = function () {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return exports.EOF_FOLLOW_KEY;\n    }\n\n    var currRuleShortName = this.getLastExplicitRuleShortName();\n    var currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    var prevRuleShortName = this.getPreviousExplicitRuleShortName();\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\n    };\n  };\n\n  Recoverable.prototype.buildFullFollowKeyStack = function () {\n    var _this = this;\n\n    var explicitRuleStack = this.RULE_STACK;\n    var explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return (0, map_1.default)(explicitRuleStack, function (ruleName, idx) {\n      if (idx === 0) {\n        return exports.EOF_FOLLOW_KEY;\n      }\n\n      return {\n        ruleName: _this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: _this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\n      };\n    });\n  };\n\n  Recoverable.prototype.flattenFollowSet = function () {\n    var _this = this;\n\n    var followStack = (0, map_1.default)(this.buildFullFollowKeyStack(), function (currKey) {\n      return _this.getFollowSetFromFollowKey(currKey);\n    });\n    return (0, flatten_1.default)(followStack);\n  };\n\n  Recoverable.prototype.getFollowSetFromFollowKey = function (followKey) {\n    if (followKey === exports.EOF_FOLLOW_KEY) {\n      return [tokens_public_1.EOF];\n    }\n\n    var followName = followKey.ruleName + followKey.idxInCallingRule + constants_1.IN + followKey.inRule;\n    return this.resyncFollows[followName];\n  }; // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n\n\n  Recoverable.prototype.addToResyncTokens = function (token, resyncTokens) {\n    if (!this.tokenMatcher(token, tokens_public_1.EOF)) {\n      resyncTokens.push(token);\n    }\n\n    return resyncTokens;\n  };\n\n  Recoverable.prototype.reSyncTo = function (tokType) {\n    var resyncedTokens = [];\n    var nextTok = this.LA(1);\n\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    } // the last token is not part of the error.\n\n\n    return (0, dropRight_1.default)(resyncedTokens);\n  };\n\n  Recoverable.prototype.attemptInRepetitionRecovery = function (prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {// by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  };\n\n  Recoverable.prototype.getCurrentGrammarPath = function (tokType, tokIdxInRule) {\n    var pathRuleStack = this.getHumanReadableRuleStack();\n    var pathOccurrenceStack = (0, clone_1.default)(this.RULE_OCCURRENCE_STACK);\n    var grammarPath = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule\n    };\n    return grammarPath;\n  };\n\n  Recoverable.prototype.getHumanReadableRuleStack = function () {\n    var _this = this;\n\n    return (0, map_1.default)(this.RULE_STACK, function (currShortName) {\n      return _this.shortRuleNameToFullName(currShortName);\n    });\n  };\n\n  return Recoverable;\n}();\n\nexports.Recoverable = Recoverable;\n\nfunction attemptInRepetitionRecovery(prodFunc, args, lookaheadFunc, dslMethodIdx, prodOccurrence, nextToksWalker, notStuck) {\n  var key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  var firstAfterRepInfo = this.firstAfterRepMap[key];\n\n  if (firstAfterRepInfo === undefined) {\n    var currRuleName = this.getCurrRuleFullName();\n    var ruleGrammar = this.getGAstProductions()[currRuleName];\n    var walker = new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n\n  var expectTokAfterLastMatch = firstAfterRepInfo.token;\n  var nextTokIdx = firstAfterRepInfo.occurrence;\n  var isEndOfRule = firstAfterRepInfo.isEndOfRule; // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n\n  if (this.RULE_STACK.length === 1 && isEndOfRule && expectTokAfterLastMatch === undefined) {\n    expectTokAfterLastMatch = tokens_public_1.EOF;\n    nextTokIdx = 1;\n  } // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n\n\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n\n  if (this.shouldInRepetitionRecoveryBeTried(expectTokAfterLastMatch, nextTokIdx, notStuck)) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(prodFunc, args, lookaheadFunc, expectTokAfterLastMatch);\n  }\n}\n\nexports.attemptInRepetitionRecovery = attemptInRepetitionRecovery;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;AASA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AAOA;;AACA;;AAEA;;AAEaA,yBAAsB,EAAtB;AAQAA,qCAA6B,yBAA7B;;AAEb;AAAA;AAAA;EAA6CC;;EAC3C,iCAAYC,OAAZ,EAA2B;IAA3B,YACEC,kBAAMD,OAAN,KAAc,IADhB;;IAEEE,KAAI,CAACC,IAAL,GAAYL,kCAAZ;;EACD;;EACH;AAAC,CALD,CAA6CM,KAA7C;;AAAaN;AAOb;;;;AAGA;AAAA;AAAA;EAAA,wBAyWC;;EApWCO,kDAAgBC,MAAhB,EAAqC;IACnC,KAAKC,gBAAL,GAAwB,EAAxB;IACA,KAAKC,aAAL,GAAqB,EAArB;IAEA,KAAKC,eAAL,GAAuB,mBAAIH,MAAJ,EAAY,iBAAZ,IAClBA,MAAM,CAACG,eADW,CACiB;IADjB,EAEnBC,+BAAsBD,eAF1B,CAJmC,CAQnC;IACA;IACA;;IACA,IAAI,KAAKA,eAAT,EAA0B;MACxB,KAAKE,2BAAL,GAAmCA,2BAAnC;IACD;EACF,CAdD;;EAgBON,yCAAP,UAAwBO,OAAxB,EAA0C;IACxC,IAAMC,WAAW,GAAG,yCAClBD,OADkB,EAElB,EAFkB,EAGlBE,GAHkB,EAIlBA,GAJkB,EAKlBA,GALkB,EAMlBA,GANkB,EAOlBA,GAPkB,EAQlBA,GARkB,CAApB;IAUAD,WAAW,CAACE,oBAAZ,GAAmC,IAAnC;IACA,OAAOF,WAAP;EACD,CAbM;;EAeAR,yDAAP,UAAwCO,OAAxC,EAA0D;IACxD,OAAO,IAAP;EACD,CAFM;;EAIAP,wDAAP,UAAuCO,OAAvC,EAAyD;IACvD,OAAO,IAAP;EACD,CAFM;;EAIPP,0DAEEW,WAFF,EAGEC,eAHF,EAIEC,aAJF,EAKEC,eALF,EAK4B;IAL5B,iBAK4B,CAE1B;;;IACA,IAAMC,aAAa,GAAG,KAAKC,mBAAL,EAAtB;IACA,IAAMC,eAAe,GAAG,KAAKC,gBAAL,EAAxB;IACA,IAAMC,cAAc,GAAa,EAAjC;IACA,IAAIC,iBAAiB,GAAG,KAAxB;IAEA,IAAMC,sBAAsB,GAAG,KAAKC,EAAL,CAAQ,CAAR,CAA/B;IACA,IAAIC,SAAS,GAAG,KAAKD,EAAL,CAAQ,CAAR,CAAhB;;IAEA,IAAME,oBAAoB,GAAG,SAAvBA,oBAAuB;MAC3B,IAAMC,aAAa,GAAG5B,KAAI,CAACyB,EAAL,CAAQ,CAAR,CAAtB,CAD2B,CAE3B;MACA;;;MACA,IAAMI,GAAG,GAAG7B,KAAI,CAAC8B,oBAAL,CAA0BC,yBAA1B,CAAoD;QAC9DC,QAAQ,EAAEf,eADoD;QAE9DgB,MAAM,EAAET,sBAFsD;QAG9DU,QAAQ,EAAEN,aAHoD;QAI9DO,QAAQ,EAAEnC,KAAI,CAACoC,mBAAL;MAJoD,CAApD,CAAZ;;MAMA,IAAMC,KAAK,GAAG,IAAIC,4CAAJ,CACZT,GADY,EAEZL,sBAFY,EAGZxB,KAAI,CAACyB,EAAL,CAAQ,CAAR,CAHY,CAAd,CAV2B,CAe3B;;MACAY,KAAK,CAACf,cAAN,GAAuB,yBAAUA,cAAV,CAAvB;;MACAtB,KAAI,CAACuC,UAAL,CAAgBF,KAAhB;IACD,CAlBD;;IAoBA,OAAO,CAACd,iBAAR,EAA2B;MACzB;MACA,IAAI,KAAKiB,YAAL,CAAkBd,SAAlB,EAA6BT,eAA7B,CAAJ,EAAmD;QACjDU,oBAAoB;QACpB,OAFiD,CAE1C;MACR,CAHD,MAGO,IAAIX,aAAa,CAACyB,IAAd,CAAmB,IAAnB,CAAJ,EAA8B;QACnC;QACAd,oBAAoB,GAFe,CAGnC;;QACAb,WAAW,CAAC4B,KAAZ,CAAkB,IAAlB,EAAwB3B,eAAxB;QACA,OALmC,CAK5B;MACR,CANM,MAMA,IAAI,KAAKyB,YAAL,CAAkBd,SAAlB,EAA6BR,aAA7B,CAAJ,EAAiD;QACtDK,iBAAiB,GAAG,IAApB;MACD,CAFM,MAEA;QACLG,SAAS,GAAG,KAAKiB,UAAL,EAAZ;QACA,KAAKC,iBAAL,CAAuBlB,SAAvB,EAAkCJ,cAAlC;MACD;IACF,CAhDyB,CAkD1B;IACA;IACA;;;IACA,KAAKuB,gBAAL,CAAsBzB,eAAtB;EACD,CA3DD;;EA6DAjB,oEAEE2C,uBAFF,EAGEC,UAHF,EAIEC,QAJF,EAI+B;IAE7B;IACA;IACA,IAAIA,QAAQ,KAAK,KAAjB,EAAwB;MACtB,OAAO,KAAP;IACD,CAN4B,CAQ7B;;;IACA,IAAI,KAAKR,YAAL,CAAkB,KAAKf,EAAL,CAAQ,CAAR,CAAlB,EAA8BqB,uBAA9B,CAAJ,EAA4D;MAC1D,OAAO,KAAP;IACD,CAX4B,CAa7B;IACA;;;IACA,IAAI,KAAKG,cAAL,EAAJ,EAA2B;MACzB,OAAO,KAAP;IACD,CAjB4B,CAmB7B;IACA;IACA;;;IACA,IACE,KAAKC,wBAAL,CACEJ,uBADF,EAEE,KAAKK,2BAAL,CAAiCL,uBAAjC,EAA0DC,UAA1D,CAFF,CADF,EAKE;MACA,OAAO,KAAP;IACD;;IAED,OAAO,IAAP;EACD,CApCD,CAzGF,CA+IE;;;EACA5C,8DAEEO,OAFF,EAGE0C,YAHF,EAGsB;IAEpB,IAAMC,WAAW,GAAG,KAAKC,qBAAL,CAA2B5C,OAA3B,EAAoC0C,YAApC,CAApB;IACA,IAAMG,OAAO,GAAG,KAAKC,yBAAL,CAA+BH,WAA/B,CAAhB;IACA,OAAOE,OAAP;EACD,CARD;;EAUApD,oDAEEc,eAFF,EAGEsC,OAHF,EAGsB;IAEpB,IAAI,KAAKE,kCAAL,CAAwCxC,eAAxC,EAAyDsC,OAAzD,CAAJ,EAAuE;MACrE,IAAM5C,WAAW,GAAG,KAAK+C,gBAAL,CAAsBzC,eAAtB,CAApB;MACA,OAAON,WAAP;IACD;;IAED,IAAI,KAAKgD,iCAAL,CAAuC1C,eAAvC,CAAJ,EAA6D;MAC3D,IAAM2C,OAAO,GAAG,KAAKjB,UAAL,EAAhB;MACA,KAAKkB,YAAL;MACA,OAAOD,OAAP;IACD;;IAED,MAAM,IAAIE,uBAAJ,CAA4B,eAA5B,CAAN;EACD,CAjBD;;EAmBA3D,2DAEE4D,aAFF,EAGER,OAHF,EAGsB;IAEpB,OACE,KAAKE,kCAAL,CAAwCM,aAAxC,EAAuDR,OAAvD,KACA,KAAKI,iCAAL,CAAuCI,aAAvC,CAFF;EAID,CATD;;EAWA5D,qEAEEc,eAFF,EAGEsC,OAHF,EAGsB;IAHtB;;IAKE,IAAI,CAAC,KAAKS,gCAAL,CAAsC/C,eAAtC,CAAL,EAA6D;MAC3D,OAAO,KAAP;IACD,CAJmB,CAMpB;;;IACA,IAAI,uBAAQsC,OAAR,CAAJ,EAAsB;MACpB,OAAO,KAAP;IACD;;IAED,IAAMU,aAAa,GAAG,KAAKxC,EAAL,CAAQ,CAAR,CAAtB;IACA,IAAMyC,wBAAwB,GAC5B,oBAAKX,OAAL,EAAc,UAACY,sBAAD,EAAkC;MAC9C,OAAOnE,KAAI,CAACwC,YAAL,CAAkByB,aAAlB,EAAiCE,sBAAjC,CAAP;IACD,CAFD,MAEOC,SAHT;IAKA,OAAOF,wBAAP;EACD,CArBD;;EAuBA/D,oEAEEc,eAFF,EAE4B;IAE1B,IAAI,CAAC,KAAKoD,+BAAL,CAAqCpD,eAArC,CAAL,EAA4D;MAC1D,OAAO,KAAP;IACD;;IAED,IAAMqD,yBAAyB,GAAG,KAAK9B,YAAL,CAChC,KAAKf,EAAL,CAAQ,CAAR,CADgC,EAEhCR,eAFgC,CAAlC;IAIA,OAAOqD,yBAAP;EACD,CAbD;;EAeAnE,2DAEEoE,YAFF,EAEyB;IAEvB,IAAMC,SAAS,GAAG,KAAKC,gBAAL,EAAlB;IACA,IAAMC,oBAAoB,GAAG,KAAKC,yBAAL,CAA+BH,SAA/B,CAA7B;IACA,OAAO,wBAASE,oBAAT,EAA+BH,YAA/B,CAAP;EACD,CAPD;;EASApE;IACE,IAAMyE,yBAAyB,GAAG,KAAKC,gBAAL,EAAlC,CADF,CAEE;;IACA,IAAIC,SAAS,GAAG,KAAKrD,EAAL,CAAQ,CAAR,CAAhB;IACA,IAAIsD,CAAC,GAAG,CAAR;;IACA,OAAO,IAAP,EAAa;MACX,IAAMC,UAAU,GAAG,oBAAKJ,yBAAL,EAAgC,UAACK,aAAD,EAAc;QAC/D,IAAMC,QAAQ,GAAG,kCAAaJ,SAAb,EAAwBG,aAAxB,CAAjB;QACA,OAAOC,QAAP;MACD,CAHkB,CAAnB;;MAIA,IAAIF,UAAU,KAAKZ,SAAnB,EAA8B;QAC5B,OAAOY,UAAP;MACD;;MACDF,SAAS,GAAG,KAAKrD,EAAL,CAAQsD,CAAR,CAAZ;MACAA,CAAC;IACF;EACF,CAhBD;;EAkBA5E;IACE;IACA,IAAI,KAAKgF,UAAL,CAAgBC,MAAhB,KAA2B,CAA/B,EAAkC;MAChC,OAAOxF,sBAAP;IACD;;IACD,IAAMyF,iBAAiB,GAAG,KAAKC,4BAAL,EAA1B;IACA,IAAMC,WAAW,GAAG,KAAKC,kCAAL,EAApB;IACA,IAAMC,iBAAiB,GAAG,KAAKC,gCAAL,EAA1B;IAEA,OAAO;MACLvD,QAAQ,EAAE,KAAKwD,uBAAL,CAA6BN,iBAA7B,CADL;MAELO,gBAAgB,EAAEL,WAFb;MAGLM,MAAM,EAAE,KAAKF,uBAAL,CAA6BF,iBAA7B;IAHH,CAAP;EAKD,CAdD;;EAgBAtF;IAAA;;IACE,IAAM2F,iBAAiB,GAAG,KAAKX,UAA/B;IACA,IAAMY,uBAAuB,GAAG,KAAKC,qBAArC;IAEA,OAAO,mBAAIF,iBAAJ,EAAuB,UAAC3D,QAAD,EAAW8D,GAAX,EAAc;MAC1C,IAAIA,GAAG,KAAK,CAAZ,EAAe;QACb,OAAOrG,sBAAP;MACD;;MACD,OAAO;QACLuC,QAAQ,EAAEnC,KAAI,CAAC2F,uBAAL,CAA6BxD,QAA7B,CADL;QAELyD,gBAAgB,EAAEG,uBAAuB,CAACE,GAAD,CAFpC;QAGLJ,MAAM,EAAE7F,KAAI,CAAC2F,uBAAL,CAA6BG,iBAAiB,CAACG,GAAG,GAAG,CAAP,CAA9C;MAHH,CAAP;IAKD,CATM,CAAP;EAUD,CAdD;;EAgBA9F;IAAA;;IACE,IAAM+F,WAAW,GAAG,mBAAI,KAAKC,uBAAL,EAAJ,EAAoC,UAACC,OAAD,EAAQ;MAC9D,OAAOpG,KAAI,CAAC2E,yBAAL,CAA+ByB,OAA/B,CAAP;IACD,CAFmB,CAApB;IAGA,OAAY,uBAAQF,WAAR,CAAZ;EACD,CALD;;EAOA/F,4DAEEqE,SAFF,EAEuB;IAErB,IAAIA,SAAS,KAAK5E,sBAAlB,EAAkC;MAChC,OAAO,CAACyG,mBAAD,CAAP;IACD;;IAED,IAAMC,UAAU,GACd9B,SAAS,CAACrC,QAAV,GAAqBqC,SAAS,CAACoB,gBAA/B,GAAkDW,cAAlD,GAAuD/B,SAAS,CAACqB,MADnE;IAGA,OAAO,KAAKvF,aAAL,CAAmBgG,UAAnB,CAAP;EACD,CAZD,CAhSF,CA8SE;EACA;;;EACAnG,oDAEEqG,KAFF,EAGEC,YAHF,EAGwB;IAEtB,IAAI,CAAC,KAAKjE,YAAL,CAAkBgE,KAAlB,EAAyBH,mBAAzB,CAAL,EAAoC;MAClCI,YAAY,CAACC,IAAb,CAAkBF,KAAlB;IACD;;IACD,OAAOC,YAAP;EACD,CATD;;EAWAtG,2CAA8BO,OAA9B,EAAgD;IAC9C,IAAMY,cAAc,GAAa,EAAjC;IACA,IAAIsC,OAAO,GAAG,KAAKnC,EAAL,CAAQ,CAAR,CAAd;;IACA,OAAO,KAAKe,YAAL,CAAkBoB,OAAlB,EAA2BlD,OAA3B,MAAwC,KAA/C,EAAsD;MACpDkD,OAAO,GAAG,KAAKjB,UAAL,EAAV;MACA,KAAKC,iBAAL,CAAuBgB,OAAvB,EAAgCtC,cAAhC;IACD,CAN6C,CAO9C;;;IACA,OAAO,yBAAUA,cAAV,CAAP;EACD,CATD;;EAWAnB,8DAEEwG,QAFF,EAGEC,IAHF,EAIEC,aAJF,EAKEC,YALF,EAMEC,cANF,EAOEC,cAPF,EAQEhE,QARF,EAQoB,CAElB;IACA;EACD,CAZD;;EAcA7C,wDAEEO,OAFF,EAGE0C,YAHF,EAGsB;IAEpB,IAAM6D,aAAa,GAAa,KAAKC,yBAAL,EAAhC;IACA,IAAMC,mBAAmB,GAAa,qBAAM,KAAKnB,qBAAX,CAAtC;IACA,IAAM3C,WAAW,GAAQ;MACvB+D,SAAS,EAAEH,aADY;MAEvBI,eAAe,EAAEF,mBAFM;MAGvBG,OAAO,EAAE5G,OAHc;MAIvB6G,iBAAiB,EAAEnE;IAJI,CAAzB;IAOA,OAAOC,WAAP;EACD,CAfD;;EAgBAlD;IAAA;;IACE,OAAO,mBAAI,KAAKgF,UAAT,EAAqB,UAACqC,aAAD,EAAc;MACxC,YAAI,CAAC7B,uBAAL,CAA6B6B,aAA7B;IAA2C,CADtC,CAAP;EAGD,CAJD;;EAKF;AAAC,CAzWD;;AAAa5H;;AA2Wb,SAAgBa,2BAAhB,CAEEkG,QAFF,EAGEC,IAHF,EAIEC,aAJF,EAKEC,YALF,EAMEC,cANF,EAOEC,cAPF,EAQEhE,QARF,EAQoB;EAElB,IAAMyE,GAAG,GAAG,KAAKC,2BAAL,CAAiCZ,YAAjC,EAA+CC,cAA/C,CAAZ;EACA,IAAIY,iBAAiB,GAAG,KAAKtH,gBAAL,CAAsBoH,GAAtB,CAAxB;;EACA,IAAIE,iBAAiB,KAAKvD,SAA1B,EAAqC;IACnC,IAAMwD,YAAY,GAAG,KAAKxF,mBAAL,EAArB;IACA,IAAMyF,WAAW,GAAG,KAAKC,kBAAL,GAA0BF,YAA1B,CAApB;IACA,IAAMG,MAAM,GACV,IAAIf,cAAJ,CAAmBa,WAAnB,EAAgCd,cAAhC,CADF;IAEAY,iBAAiB,GAAGI,MAAM,CAACC,YAAP,EAApB;IACA,KAAK3H,gBAAL,CAAsBoH,GAAtB,IAA6BE,iBAA7B;EACD;;EAED,IAAI7E,uBAAuB,GAAG6E,iBAAiB,CAACnB,KAAhD;EACA,IAAIzD,UAAU,GAAG4E,iBAAiB,CAACM,UAAnC;EACA,IAAMC,WAAW,GAAGP,iBAAiB,CAACO,WAAtC,CAfkB,CAiBlB;EACA;;EACA,IACE,KAAK/C,UAAL,CAAgBC,MAAhB,KAA2B,CAA3B,IACA8C,WADA,IAEApF,uBAAuB,KAAKsB,SAH9B,EAIE;IACAtB,uBAAuB,GAAGuD,mBAA1B;IACAtD,UAAU,GAAG,CAAb;EACD,CA1BiB,CA4BlB;EACA;;;EACA,IAAID,uBAAuB,KAAKsB,SAA5B,IAAyCrB,UAAU,KAAKqB,SAA5D,EAAuE;IACrE;EACD;;EAED,IACE,KAAK+D,iCAAL,CACErF,uBADF,EAEEC,UAFF,EAGEC,QAHF,CADF,EAME;IACA;IACA;IACA;IACA,KAAKoF,uBAAL,CACEzB,QADF,EAEEC,IAFF,EAGEC,aAHF,EAIE/D,uBAJF;EAMD;AACF;;AA3DDlD","names":["exports","__extends","message","_super","_this","name","Error","Recoverable","config","firstAfterRepMap","resyncFollows","recoveryEnabled","parser_1","attemptInRepetitionRecovery","tokType","tokToInsert","NaN","isInsertedInRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","resyncedTokens","passedResyncPoint","nextTokenWithoutResync","LA","currToken","generateErrorMessage","previousToken","msg","errorMessageProvider","buildMismatchTokenMessage","expected","actual","previous","ruleName","getCurrRuleFullName","error","exceptions_public_1","SAVE_ERROR","tokenMatcher","call","apply","SKIP_TOKEN","addToResyncTokens","importLexerState","expectTokAfterLastMatch","nextTokIdx","notStuck","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","follows","getNextPossibleTokenTypes","canRecoverWithSingleTokenInsertion","getTokenToInsert","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","InRuleRecoveryException","expectedToken","canTokenTypeBeInsertedInRecovery","mismatchedTok","isMisMatchedTokInFollows","possibleFollowsTokType","undefined","canTokenTypeBeDeletedInRecovery","isNextTokenWhatIsExpected","tokenTypeIdx","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","allPossibleReSyncTokTypes","flattenFollowSet","nextToken","k","foundMatch","resyncTokType","canMatch","RULE_STACK","length","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","idx","followStack","buildFullFollowKeyStack","currKey","tokens_public_1","followName","constants_1","token","resyncTokens","push","prodFunc","args","lookaheadFunc","dslMethodIdx","prodOccurrence","nextToksWalker","pathRuleStack","getHumanReadableRuleStack","pathOccurrenceStack","ruleStack","occurrenceStack","lastTok","lastTokOccurrence","currShortName","key","getKeyForAutomaticLookahead","firstAfterRepInfo","currRuleName","ruleGrammar","getGAstProductions","walker","startWalking","occurrence","isEndOfRule","shouldInRepetitionRecoveryBeTried","tryInRepetitionRecovery"],"sources":["D:\\Github\\NIKE-DJANGO\\Jord\\l4fycy\\node_modules\\chevrotain\\src\\parse\\parser\\traits\\recoverable.ts"],"sourcesContent":["import {\r\n  createTokenInstance,\r\n  EOF,\r\n  tokenMatcher\r\n} from \"../../../scan/tokens_public\"\r\nimport {\r\n  AbstractNextTerminalAfterProductionWalker,\r\n  IFirstAfterRepetition\r\n} from \"../../grammar/interpreter\"\r\nimport isEmpty from \"lodash/isEmpty\"\r\nimport dropRight from \"lodash/dropRight\"\r\nimport flatten from \"lodash/flatten\"\r\nimport map from \"lodash/map\"\r\nimport find from \"lodash/find\"\r\nimport has from \"lodash/has\"\r\nimport includes from \"lodash/includes\"\r\nimport clone from \"lodash/clone\"\r\nimport {\r\n  IParserConfig,\r\n  IToken,\r\n  ITokenGrammarPath,\r\n  TokenType\r\n} from \"@chevrotain/types\"\r\nimport { MismatchedTokenException } from \"../../exceptions_public\"\r\nimport { IN } from \"../../constants\"\r\nimport { MixedInParser } from \"./parser_traits\"\r\nimport { DEFAULT_PARSER_CONFIG } from \"../parser\"\r\n\r\nexport const EOF_FOLLOW_KEY: any = {}\r\n\r\nexport interface IFollowKey {\r\n  ruleName: string\r\n  idxInCallingRule: number\r\n  inRule: string\r\n}\r\n\r\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\"\r\n\r\nexport class InRuleRecoveryException extends Error {\r\n  constructor(message: string) {\r\n    super(message)\r\n    this.name = IN_RULE_RECOVERY_EXCEPTION\r\n  }\r\n}\r\n\r\n/**\r\n * This trait is responsible for the error recovery and fault tolerant logic\r\n */\r\nexport class Recoverable {\r\n  recoveryEnabled: boolean\r\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>\r\n  resyncFollows: Record<string, TokenType[]>\r\n\r\n  initRecoverable(config: IParserConfig) {\r\n    this.firstAfterRepMap = {}\r\n    this.resyncFollows = {}\r\n\r\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\r\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\r\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled\r\n\r\n    // performance optimization, NOOP will be inlined which\r\n    // effectively means that this optional feature does not exist\r\n    // when not used.\r\n    if (this.recoveryEnabled) {\r\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery\r\n    }\r\n  }\r\n\r\n  public getTokenToInsert(tokType: TokenType): IToken {\r\n    const tokToInsert = createTokenInstance(\r\n      tokType,\r\n      \"\",\r\n      NaN,\r\n      NaN,\r\n      NaN,\r\n      NaN,\r\n      NaN,\r\n      NaN\r\n    )\r\n    tokToInsert.isInsertedInRecovery = true\r\n    return tokToInsert\r\n  }\r\n\r\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\r\n    return true\r\n  }\r\n\r\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\r\n    return true\r\n  }\r\n\r\n  tryInRepetitionRecovery(\r\n    this: MixedInParser,\r\n    grammarRule: Function,\r\n    grammarRuleArgs: any[],\r\n    lookAheadFunc: () => boolean,\r\n    expectedTokType: TokenType\r\n  ): void {\r\n    // TODO: can the resyncTokenType be cached?\r\n    const reSyncTokType = this.findReSyncTokenType()\r\n    const savedLexerState = this.exportLexerState()\r\n    const resyncedTokens: IToken[] = []\r\n    let passedResyncPoint = false\r\n\r\n    const nextTokenWithoutResync = this.LA(1)\r\n    let currToken = this.LA(1)\r\n\r\n    const generateErrorMessage = () => {\r\n      const previousToken = this.LA(0)\r\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\r\n      // the error that would have been thrown\r\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\r\n        expected: expectedTokType,\r\n        actual: nextTokenWithoutResync,\r\n        previous: previousToken,\r\n        ruleName: this.getCurrRuleFullName()\r\n      })\r\n      const error = new MismatchedTokenException(\r\n        msg,\r\n        nextTokenWithoutResync,\r\n        this.LA(0)\r\n      )\r\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\r\n      error.resyncedTokens = dropRight(resyncedTokens)\r\n      this.SAVE_ERROR(error)\r\n    }\r\n\r\n    while (!passedResyncPoint) {\r\n      // re-synced to a point where we can safely exit the repetition/\r\n      if (this.tokenMatcher(currToken, expectedTokType)) {\r\n        generateErrorMessage()\r\n        return // must return here to avoid reverting the inputIdx\r\n      } else if (lookAheadFunc.call(this)) {\r\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\r\n        generateErrorMessage()\r\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\r\n        grammarRule.apply(this, grammarRuleArgs)\r\n        return // must return here to avoid reverting the inputIdx\r\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\r\n        passedResyncPoint = true\r\n      } else {\r\n        currToken = this.SKIP_TOKEN()\r\n        this.addToResyncTokens(currToken, resyncedTokens)\r\n      }\r\n    }\r\n\r\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\r\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\r\n    // \"between rules\" resync recovery later in the flow.\r\n    this.importLexerState(savedLexerState)\r\n  }\r\n\r\n  shouldInRepetitionRecoveryBeTried(\r\n    this: MixedInParser,\r\n    expectTokAfterLastMatch: TokenType,\r\n    nextTokIdx: number,\r\n    notStuck: boolean | undefined\r\n  ): boolean {\r\n    // Edge case of arriving from a MANY repetition which is stuck\r\n    // Attempting recovery in this case could cause an infinite loop\r\n    if (notStuck === false) {\r\n      return false\r\n    }\r\n\r\n    // no need to recover, next token is what we expect...\r\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\r\n      return false\r\n    }\r\n\r\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\r\n    // and prefer some backtracking path that includes recovered errors.\r\n    if (this.isBackTracking()) {\r\n      return false\r\n    }\r\n\r\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\r\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\r\n    //noinspection RedundantIfStatementJS\r\n    if (\r\n      this.canPerformInRuleRecovery(\r\n        expectTokAfterLastMatch,\r\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx)\r\n      )\r\n    ) {\r\n      return false\r\n    }\r\n\r\n    return true\r\n  }\r\n\r\n  // Error Recovery functionality\r\n  getFollowsForInRuleRecovery(\r\n    this: MixedInParser,\r\n    tokType: TokenType,\r\n    tokIdxInRule: number\r\n  ): TokenType[] {\r\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule)\r\n    const follows = this.getNextPossibleTokenTypes(grammarPath)\r\n    return follows\r\n  }\r\n\r\n  tryInRuleRecovery(\r\n    this: MixedInParser,\r\n    expectedTokType: TokenType,\r\n    follows: TokenType[]\r\n  ): IToken {\r\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\r\n      const tokToInsert = this.getTokenToInsert(expectedTokType)\r\n      return tokToInsert\r\n    }\r\n\r\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\r\n      const nextTok = this.SKIP_TOKEN()\r\n      this.consumeToken()\r\n      return nextTok\r\n    }\r\n\r\n    throw new InRuleRecoveryException(\"sad sad panda\")\r\n  }\r\n\r\n  canPerformInRuleRecovery(\r\n    this: MixedInParser,\r\n    expectedToken: TokenType,\r\n    follows: TokenType[]\r\n  ): boolean {\r\n    return (\r\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\r\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\r\n    )\r\n  }\r\n\r\n  canRecoverWithSingleTokenInsertion(\r\n    this: MixedInParser,\r\n    expectedTokType: TokenType,\r\n    follows: TokenType[]\r\n  ): boolean {\r\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\r\n      return false\r\n    }\r\n\r\n    // must know the possible following tokens to perform single token insertion\r\n    if (isEmpty(follows)) {\r\n      return false\r\n    }\r\n\r\n    const mismatchedTok = this.LA(1)\r\n    const isMisMatchedTokInFollows =\r\n      find(follows, (possibleFollowsTokType: TokenType) => {\r\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType)\r\n      }) !== undefined\r\n\r\n    return isMisMatchedTokInFollows\r\n  }\r\n\r\n  canRecoverWithSingleTokenDeletion(\r\n    this: MixedInParser,\r\n    expectedTokType: TokenType\r\n  ): boolean {\r\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\r\n      return false\r\n    }\r\n\r\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\r\n      this.LA(2),\r\n      expectedTokType\r\n    )\r\n    return isNextTokenWhatIsExpected\r\n  }\r\n\r\n  isInCurrentRuleReSyncSet(\r\n    this: MixedInParser,\r\n    tokenTypeIdx: TokenType\r\n  ): boolean {\r\n    const followKey = this.getCurrFollowKey()\r\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey)\r\n    return includes(currentRuleReSyncSet, tokenTypeIdx)\r\n  }\r\n\r\n  findReSyncTokenType(this: MixedInParser): TokenType {\r\n    const allPossibleReSyncTokTypes = this.flattenFollowSet()\r\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\r\n    let nextToken = this.LA(1)\r\n    let k = 2\r\n    while (true) {\r\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\r\n        const canMatch = tokenMatcher(nextToken, resyncTokType)\r\n        return canMatch\r\n      })\r\n      if (foundMatch !== undefined) {\r\n        return foundMatch\r\n      }\r\n      nextToken = this.LA(k)\r\n      k++\r\n    }\r\n  }\r\n\r\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\r\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\r\n    if (this.RULE_STACK.length === 1) {\r\n      return EOF_FOLLOW_KEY\r\n    }\r\n    const currRuleShortName = this.getLastExplicitRuleShortName()\r\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex()\r\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName()\r\n\r\n    return {\r\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\r\n      idxInCallingRule: currRuleIdx,\r\n      inRule: this.shortRuleNameToFullName(prevRuleShortName)\r\n    }\r\n  }\r\n\r\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\r\n    const explicitRuleStack = this.RULE_STACK\r\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK\r\n\r\n    return map(explicitRuleStack, (ruleName, idx) => {\r\n      if (idx === 0) {\r\n        return EOF_FOLLOW_KEY\r\n      }\r\n      return {\r\n        ruleName: this.shortRuleNameToFullName(ruleName),\r\n        idxInCallingRule: explicitOccurrenceStack[idx],\r\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1])\r\n      }\r\n    })\r\n  }\r\n\r\n  flattenFollowSet(this: MixedInParser): TokenType[] {\r\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\r\n      return this.getFollowSetFromFollowKey(currKey)\r\n    })\r\n    return <any>flatten(followStack)\r\n  }\r\n\r\n  getFollowSetFromFollowKey(\r\n    this: MixedInParser,\r\n    followKey: IFollowKey\r\n  ): TokenType[] {\r\n    if (followKey === EOF_FOLLOW_KEY) {\r\n      return [EOF]\r\n    }\r\n\r\n    const followName =\r\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule\r\n\r\n    return this.resyncFollows[followName]\r\n  }\r\n\r\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\r\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\r\n  addToResyncTokens(\r\n    this: MixedInParser,\r\n    token: IToken,\r\n    resyncTokens: IToken[]\r\n  ): IToken[] {\r\n    if (!this.tokenMatcher(token, EOF)) {\r\n      resyncTokens.push(token)\r\n    }\r\n    return resyncTokens\r\n  }\r\n\r\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\r\n    const resyncedTokens: IToken[] = []\r\n    let nextTok = this.LA(1)\r\n    while (this.tokenMatcher(nextTok, tokType) === false) {\r\n      nextTok = this.SKIP_TOKEN()\r\n      this.addToResyncTokens(nextTok, resyncedTokens)\r\n    }\r\n    // the last token is not part of the error.\r\n    return dropRight(resyncedTokens)\r\n  }\r\n\r\n  attemptInRepetitionRecovery(\r\n    this: MixedInParser,\r\n    prodFunc: Function,\r\n    args: any[],\r\n    lookaheadFunc: () => boolean,\r\n    dslMethodIdx: number,\r\n    prodOccurrence: number,\r\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\r\n    notStuck?: boolean\r\n  ): void {\r\n    // by default this is a NO-OP\r\n    // The actual implementation is with the function(not method) below\r\n  }\r\n\r\n  getCurrentGrammarPath(\r\n    this: MixedInParser,\r\n    tokType: TokenType,\r\n    tokIdxInRule: number\r\n  ): ITokenGrammarPath {\r\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack()\r\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK)\r\n    const grammarPath: any = {\r\n      ruleStack: pathRuleStack,\r\n      occurrenceStack: pathOccurrenceStack,\r\n      lastTok: tokType,\r\n      lastTokOccurrence: tokIdxInRule\r\n    }\r\n\r\n    return grammarPath\r\n  }\r\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\r\n    return map(this.RULE_STACK, (currShortName) =>\r\n      this.shortRuleNameToFullName(currShortName)\r\n    )\r\n  }\r\n}\r\n\r\nexport function attemptInRepetitionRecovery(\r\n  this: MixedInParser,\r\n  prodFunc: Function,\r\n  args: any[],\r\n  lookaheadFunc: () => boolean,\r\n  dslMethodIdx: number,\r\n  prodOccurrence: number,\r\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\r\n  notStuck?: boolean\r\n): void {\r\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence)\r\n  let firstAfterRepInfo = this.firstAfterRepMap[key]\r\n  if (firstAfterRepInfo === undefined) {\r\n    const currRuleName = this.getCurrRuleFullName()\r\n    const ruleGrammar = this.getGAstProductions()[currRuleName]\r\n    const walker: AbstractNextTerminalAfterProductionWalker =\r\n      new nextToksWalker(ruleGrammar, prodOccurrence)\r\n    firstAfterRepInfo = walker.startWalking()\r\n    this.firstAfterRepMap[key] = firstAfterRepInfo\r\n  }\r\n\r\n  let expectTokAfterLastMatch = firstAfterRepInfo.token\r\n  let nextTokIdx = firstAfterRepInfo.occurrence\r\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule\r\n\r\n  // special edge case of a TOP most repetition after which the input should END.\r\n  // this will force an attempt for inRule recovery in that scenario.\r\n  if (\r\n    this.RULE_STACK.length === 1 &&\r\n    isEndOfRule &&\r\n    expectTokAfterLastMatch === undefined\r\n  ) {\r\n    expectTokAfterLastMatch = EOF\r\n    nextTokIdx = 1\r\n  }\r\n\r\n  // We don't have anything to re-sync to...\r\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\r\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\r\n    return\r\n  }\r\n\r\n  if (\r\n    this.shouldInRepetitionRecoveryBeTried(\r\n      expectTokAfterLastMatch,\r\n      nextTokIdx,\r\n      notStuck\r\n    )\r\n  ) {\r\n    // TODO: performance optimization: instead of passing the original args here, we modify\r\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\r\n    // to avoid searching the cache for it once more.\r\n    this.tryInRepetitionRecovery(\r\n      prodFunc,\r\n      args,\r\n      lookaheadFunc,\r\n      expectTokAfterLastMatch\r\n    )\r\n  }\r\n}\r\n"]},"metadata":{},"sourceType":"script"}